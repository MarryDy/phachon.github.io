{"meta":{"title":"phachon's blog","subtitle":"notes blog","description":"好像什么都没有","author":"phachon","url":"http://phachon.github.io"},"pages":[{"title":"关于","date":"2018-09-13T13:02:05.667Z","updated":"2018-09-13T13:02:05.667Z","comments":true,"path":"about/index.html","permalink":"http://phachon.github.io/about/index.html","excerpt":"","text":""},{"title":"开源项目","date":"2018-04-12T16:00:00.000Z","updated":"2018-09-13T13:02:05.675Z","comments":true,"path":"opensource/index.html","permalink":"http://phachon.github.io/opensource/index.html","excerpt":"","text":"以下是本人的一些开源项目, 欢迎 Star 或 Fork codepub 一个快速可持续的Git代码发布系统 MM-Wiki 一个轻量级的企业知识分享与团队协同软件，可用于快速构建企业 Wiki 和团队知识分享平台 go-logger 一个简单而强大的 golang 日志工具包 wmqx 一个基于 Rabbitmq 的 Http 消息推送服务 fasthttpsession 一个快速且强大的 fasthttp session 管理包 一些 html、bootstrap框架的后台模板集合"},{"title":"分类","date":"2018-09-13T13:02:05.667Z","updated":"2018-09-13T13:02:05.667Z","comments":true,"path":"categories/index.html","permalink":"http://phachon.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-09-13T13:02:05.675Z","updated":"2018-09-13T13:02:05.675Z","comments":true,"path":"tags/index.html","permalink":"http://phachon.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"TCP/IP 协议栈系列（十三）：IP协议简单介绍","slug":"TCP_IP_13","date":"2018-09-21T16:00:00.000Z","updated":"2018-09-21T13:42:32.493Z","comments":true,"path":"2018/09/22/TCP_IP_13/","link":"","permalink":"http://phachon.github.io/2018/09/22/TCP_IP_13/","excerpt":"","text":"","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（十二）：DNS原理分析","slug":"TCP_IP_12","date":"2018-09-20T16:00:00.000Z","updated":"2018-09-21T13:42:32.493Z","comments":true,"path":"2018/09/21/TCP_IP_12/","link":"","permalink":"http://phachon.github.io/2018/09/21/TCP_IP_12/","excerpt":"","text":"","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（十一）：UDP协议详解","slug":"TCP_IP_11","date":"2018-09-19T16:00:00.000Z","updated":"2018-09-21T13:42:32.492Z","comments":true,"path":"2018/09/20/TCP_IP_11/","link":"","permalink":"http://phachon.github.io/2018/09/20/TCP_IP_11/","excerpt":"","text":"","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（十）：TLS/SSL握手过程","slug":"TCP_IP_10","date":"2018-09-18T16:00:00.000Z","updated":"2018-09-21T13:42:32.492Z","comments":true,"path":"2018/09/19/TCP_IP_10/","link":"","permalink":"http://phachon.github.io/2018/09/19/TCP_IP_10/","excerpt":"","text":"","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（九）：TLS/SSL握手过程","slug":"TCP_IP_9","date":"2018-09-17T16:00:00.000Z","updated":"2018-09-21T13:42:32.496Z","comments":true,"path":"2018/09/18/TCP_IP_9/","link":"","permalink":"http://phachon.github.io/2018/09/18/TCP_IP_9/","excerpt":"","text":"","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（八）：HTTPS证书原理","slug":"TCP_IP_8","date":"2018-09-16T16:00:00.000Z","updated":"2018-09-21T13:42:32.496Z","comments":true,"path":"2018/09/17/TCP_IP_8/","link":"","permalink":"http://phachon.github.io/2018/09/17/TCP_IP_8/","excerpt":"","text":"","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（七）：HTTPS基础知识","slug":"TCP_IP_7","date":"2018-09-15T16:00:00.000Z","updated":"2018-09-21T13:42:32.495Z","comments":true,"path":"2018/09/16/TCP_IP_7/","link":"","permalink":"http://phachon.github.io/2018/09/16/TCP_IP_7/","excerpt":"","text":"","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（六）：HTTP2.0协议详解","slug":"TCP_IP_6","date":"2018-09-14T16:00:00.000Z","updated":"2018-09-21T13:42:32.495Z","comments":true,"path":"2018/09/15/TCP_IP_6/","link":"","permalink":"http://phachon.github.io/2018/09/15/TCP_IP_6/","excerpt":"","text":"","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（五）：HTTP1.0与HTTP1.1协议详解","slug":"TCP_IP_5","date":"2018-09-13T16:00:00.000Z","updated":"2018-09-21T13:42:32.495Z","comments":true,"path":"2018/09/14/TCP_IP_5/","link":"","permalink":"http://phachon.github.io/2018/09/14/TCP_IP_5/","excerpt":"","text":"","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（四）：HTTP协议概述","slug":"TCP_IP_4","date":"2018-09-12T16:00:00.000Z","updated":"2018-09-21T13:42:32.494Z","comments":true,"path":"2018/09/13/TCP_IP_4/","link":"","permalink":"http://phachon.github.io/2018/09/13/TCP_IP_4/","excerpt":"","text":"","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（三）：TCP协议详解","slug":"TCP_IP_3","date":"2018-09-11T16:00:00.000Z","updated":"2018-09-21T13:42:32.494Z","comments":true,"path":"2018/09/12/TCP_IP_3/","link":"","permalink":"http://phachon.github.io/2018/09/12/TCP_IP_3/","excerpt":"","text":"","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（二）：协议概述","slug":"TCP_IP_2","date":"2018-09-10T16:00:00.000Z","updated":"2018-09-22T02:03:51.809Z","comments":true,"path":"2018/09/11/TCP_IP_2/","link":"","permalink":"http://phachon.github.io/2018/09/11/TCP_IP_2/","excerpt":"","text":"本章将自底向上来说明 TCP/IP协议栈各层的具体工作流程 传输介质首先，我们应该都知道计算机之间必须通过一定的传输媒介才能将数据相互传递，例如，光缆，光纤，或者无线电波，不同的传输媒介决定了电信号（0 1）的传输方式，同时也影响了电信号的传输速率、传输带宽。 链路层我们自然的会去思考： 如何才能将 0 1 的电信号通过传输媒介传输到对方的主机？ 很好解决：我们将每个计算机都安装一个能接受数据和发送数据的设备，然后将 0 1 的电信号分组，也就是组成字节的形式发送出去。 为什么要组成字节发送，因为单纯的 0 1 是没有意义的，计算机用 8 个 0 或 1 的二进制位来表示一个字节，字节才是我们发送数据的最小单位 那么这里我们提到的接受数据和发送数据的设备，就是网卡。我们规定，数据包必须是从一块网卡到另一块网卡，而网卡的地址（即我们常说的MAC 地址）就是数据包要发送的地址和接受地址。MAC 地址就像网卡的身份证一样，必须具有全球唯一性。MAC 地址采用 16 进制表示，共 6 个字节，前 3 个字节是厂商的编号，后三个字节是网卡流水号。例如：5C-0F-6E-13-D1-18 解决了发送设备，接下来解决如何发送，所以就有人设计出来了一种发送数据的规范，也就是以太网协议。 以太网协议规定，一组电信号就是一个数据包，一个数据包也被称为一帧。一个以太网数据包的格式如下： 123+--------------+----------------------+--------------+| head(14 byte)| data(46 ~ 1500 byte) | end (4 byte) |+--------------+----------------------+--------------+ 整个数据包由三部分组成，头部，数据，和尾部，头部占14个字节，包含原MAC地址，目标MAC地址和类型；数据区最短 46个字节，最大 1500 个字节，如果发送的数据大于 1500 个字节，则必须拆开多个数据包来发送。尾部为 4 个字节，用来存数据帧的校验序列，用来验证整个数据包是否完整。 以太网数据包发送过程：以太网协议会通过广播的形式将以太网数据包发送给在同一个子网的所有主机，这些主机接受到数据包之后，会取出数据包的头部里的 MAC 地址和自己的 MAC 地址进行比较，如果相等，就会接着处理数据，如果不相等，则会丢弃这个数据包。 总结：链路层的工作就是将 0，1的电信号分组并组装成以太网数据包，然后网卡通过传输媒介以广播的形式将数据包发送给在同一个子网的接收方 注意：以太网协议始终是以广播的形式将数据包发给在同一个子网的主机 网络层首先再回过头来看一下链路层，为了能让链路层工作，我们必须知道对方主机的 MAC 地址，而且还要知道对方的 MAC 地址是否和自己处于同一网络。 如果我们使用 MAC 地址来传输数据，那就必须记住每个 MAC 地址，但是去记一串这样长（ 5C-0F-6E-13-D1-18 ）的地址显然是不友好的 即使我们能记住 MAC 地址，MAC 地址也只于厂商有关，和网络无关，怎么能知道是不是在一个子网？ 如果不是一个子网，那怎么办，以太网的协议难道不能发生以太网数据包了？ 别急，能提出问题，那自然有解决方案，当没有解决办法的时候，那就设计一套新的协议来弥补这些问题。 为了解决以上的问题，我们的前辈们设计了三个协议：IP 协议，ARP 协议，路由协议。同时呢将这三个协议放在了网路层。 IP 协议为了解决 1 和 2，必须指定了一套新的地址。使得我们能够区分两个主机是否在同一个网络。IP 地址分为 IPV4 和 IPV6 两种，现在普遍还在使用的是 IPV4 地址，IPV4 地址由 4 个字节 32 位组成，每个字节可以用一个十进制的数表示，通常，我们使用 . 隔开每个十进制数来表示 ip 地址，例如：192.168.12.11 。同时，IPV4 对 IP 地址进行了分类，主要是 A B C D 四类，以 C 类地址 192.168.12.11 为例，其中前 24 位就是网络地址，后 8 位就是主机地址。那么网络地址相同的就是在一个局域网子网内为了判断 IP 地址中的网络地址，IP 协议还引入了子网掩码，通过子网掩码和 IP 地址按位与运算，就能得到网络地址。 因为在上层的传输层中，开发者会将 IP 地址传入，所以我们只用通过子网掩码进行运算后就能判断两个 IP 是否在一个子网内。 这里简单介绍一下 IP 数据包： 123+-----------------+--------------------+| head(20 byte) | data (65515 byte) |+----------------=+--------------------+ ARP 协议我们解决了问题1和问题2，但是随之问题又来 现在设计的 IP 协议解决了在不在一个子网内的问题，但是如果用 IP 协议，以太网协议必须知道目标主机的 MAC 地址才能传输，怎么获取到目前主机的 MAC 地址？ 为了解决这个问题，ARP 协议被设计出来，即 IP 地址解析协议，主要作用就是通过 IP 来获取到对应的 MAC 地址。 ARP 协议的具体工作过程：ARP 会首先发起一个数据包，数据包里面包含了目标主机的 IP 地址，然后发送到链路层再次包装成以太网数据包，最终由以太网广播给自己当前子网的所有主机，主机接受到这个数据包之后，取出数据包的 IP 地址，和自己的 IP 地址进行对比如果相同就返回自己的 MAC 地址，如果不同就丢弃这个数据包。ARP 接受消息来确定目标主机的 MAC 地址。如果查询到了 MAC 地址，ARP 还会将该 IP 的 MAC 地址缓存到本机保留一段时间等下次再有请求查询，直接先从缓存里取出。这样可以节约资源，提高查询效率。 相反的 RARP 协议是用来解析 MAC 地址为 IP 地址的协议 路由协议我们发现 ARP 协议通过 IP 获取 MAC 地址依然是局限在子网内，那不在子网的 IP 地址，ARP 不就拿不到 MAC 地址了？这也就是我们开始提出的第三个问题还没有解决。 为了解决这个问题，前辈们又设计出了另一种协议-路由协议，路由协议必须借助路由设备来完成，即路由器或交换机，路由器扮演着交通枢纽的角色，会根据信道的情况，选择合适的路径来转发数据包因此，刚刚我们的那个问题得到解决，首先是通过 IP 协议来判断两个 IP 是否在同一个子网内，如果在一个子网，那就通过 ARP 协议去获取 MAC 地址，然后再通过以太网协议将数据包广播到子网内；如果不在一个子网内，以太网会将数据包先转发到本子网的网关进行路由，网关会进行多次转发，并最终将数据包转发到目标 IP 的子网内，然后再通过 ARP 协议获取目标主机的 MAC 地址，最终再通过以太网协议将数据包发送到目标 MAC 地址。 总结一下：网络层的工作主要是定义网络地址、划分网段、查询 MAC 地址、对不是同一网段的数据包进行路由转发 传输层依靠传输层和链路层的工作，数据已经能够正常的从一台主机发送到另一台主机，但是，我们在一台主机中往往不可能只有一个网络程序，所以当又多个网络程序同时工作的时候，我们依然会发现有如下问题 如何在多个网络程序运行的主机间进行数据传输，更简单的来说，就是如何一个主机的某个应用程序发出，然后由对方主机的应用程序接收？ 为了解决这个问题，聪明的前辈们又想到了解决办法，为每一个网络程序分配一个不同的数字来表示，发送数据的时候指定发送到某台主机的某个数字的网络程序不就可以了。这个数字就是端口。端口用 2 个字节来表示，范围是 0 ～ 65535，也就是最大 65535 个端口。一般情况下是足够用了。有了端口，我们来简单介绍下传输层的两种协议。 TCP我们知道网络层的数据包 IP 数据包都是不保证可靠性的，也就是说将数据发送出去，并不保证数据可达，并且数据发送也不保证有序。所以，为了满足一些对数据可靠性和有序性的应用。前辈们设计了新的协议TCP 协议。TCP 协议是保证了数据的可靠性，有序性，面向连接的传输协议。如果发现有一个数据包收不到确认，就重新发送数据包。 有了 TCP 协议，我们的应该程序可以将数据有序的，可靠的发送到对方指定端口的网络程序中。TCP 数据包格式 123+-----------------+--------------------+| head(20 byte) | data |+----------------=+--------------------+ TCP 建立连接需要经过 3 次握手，断开连接需要经过 4 次挥手。后面章节会详细来讲解整个过程，再次不详细讨论 UDP 不一定是所有的场景都必须要求数据的可靠性和有序性，有些应用程序只要求数据能快速高效的发送出去，至于可靠性并不十分关系，那这个时候 TCP 协议似乎不能满足这种需求。 其实 IP 协议的数据包就可以满足我们的新的需求，但是 IP 协议是网络层，不存在端口。而我们在传输层规定了端口，所以干脆就在传输层新设计一个协议 UDP 协议，UDP 协议其实就是在 IP 协议的基础上指定了端口（简单理解）。 UDP 是面向用户的（非连接的）传输层协议，这是因为 UDP 不像 TCP 需要 3 次握手建立连接的机制。UDP 协议相较于 TCP 来说实现比较简单，没有确认机制，数据包一旦发出，不保证数据可达和有序。不过一般情况下 UDP的数据包也不会有那么差的可靠性，还是能保证一定的可靠性。但是相较于 TCP ，UDP 的发送效率是比较快的。UDP 数据包的格式如下 123+-----------------+--------------------+| head(8 byte) | data (65527 byte) |+----------------=+--------------------+ 应用层有了上面介绍的三层协议的支持，我们可以满足各种情况下，将我们的数据包发送到指定的端口的网络程序中，但是，传输的数据都是字节流，程序并不能很好的识别，操作性相对比较差。因此，在应用层规范了各种各样的协议来规范我们的数据格式，同时也使得我们程序开发更为便利。常见的应用层协议有：HTTP、FTP、SMTP 等。针对不同类型的应用程序开发，可以使用不同的协议来开发。 每天在浏览器浏览网页，我们最熟悉的莫过于 HTTP 协议了。后面我会有专门的章节来详细讲解 HTTP 协议，这里不做过多介绍。 总结有了分层的模型，每一层基于协议又有非常明确的分工，使得计算机之间的数据传输有条不紊的进行。我们来自顶向下回顾一下每一层的数据传输过程： 应用层：应用层将用户输入的数据规范化，并根据应用层协议（如 HTTP 协议）封装成数据消息，传输给传输层 传输层：传输层拿到应用层消息，根据传输层协议，将数据再次包装，并加上传输层协议头，发给网络层 网络层：拿到传输层数据包，根据 IP 协议，将数据再次包装，加上 IP 协议头，发送给链路层 链路层：链路层拿到网络层数据包，再次包装层以太网数据包，加上以太网协议头。通过网卡发送给对方主机 再来自顶向下回顾一下每一层的职责： 应用层：按照应用层协议解析和规范用户数据 传输层：定义端口，确定要发送的目标主机上的应用程序，根据协议的不同，控制数据的传输 网络层：定义 IP 地址；分配网络地址和主机地址；解析 MAC 地址；将不在同一子网的数据包路由转发 链路层：对 0 1进行分组，定义数据帧，确认对方主机 MAC 地址。通过物理媒介传输到对方主机的网卡 本文只是对 TCP/IP 协议栈各个层工作的一个概述，具体每一层的协议，后面会有专门的章节来介绍。 参考文献 深入浅出 TCP/IP 协议栈","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（一）：模型简介","slug":"TCP_IP_1","date":"2018-09-09T16:00:00.000Z","updated":"2018-09-21T13:42:32.492Z","comments":true,"path":"2018/09/10/TCP_IP_1/","link":"","permalink":"http://phachon.github.io/2018/09/10/TCP_IP_1/","excerpt":"本系列将由浅入深通俗的讲解 TCP/IP 协议栈的基本知识，希望能对读者有用。 OSI 七层模型TCP/IP 协议栈是在借鉴了 OSI 七层模型的基础上提出来的模型，所以我们有必要先来了解一下 OSI 七层模型。 OSI 模型是计算机网路体系结构发展的产物。它的基本内容是开放系统通信功能的分层结构。通俗来讲，就是为了计算机系统的通信功能设计的一套标准的框架，大家都遵循这套标准来进行网络通信的开发，OSI 七层模型如下：","text":"本系列将由浅入深通俗的讲解 TCP/IP 协议栈的基本知识，希望能对读者有用。 OSI 七层模型TCP/IP 协议栈是在借鉴了 OSI 七层模型的基础上提出来的模型，所以我们有必要先来了解一下 OSI 七层模型。 OSI 模型是计算机网路体系结构发展的产物。它的基本内容是开放系统通信功能的分层结构。通俗来讲，就是为了计算机系统的通信功能设计的一套标准的框架，大家都遵循这套标准来进行网络通信的开发，OSI 七层模型如下： 应用称 表示层 会话层 传输层 网络层 数据链路层 物理层 具体每一层的作用，这里不再详细说明； TCP/IP 四层模型TCP/IP 协议栈基于 OSI 七层模型提出来 TCP/IP 四层模型，也就是简化了的 OSI 模型： 应用层 传输称 网络层 链路层 OSI 七层模型和 TCP/IP 4 层模型之间的关系如下： 对比总结OSI 七层模型 主要概念：服务，接口，协议 协议有很好的隐蔽性 产生在协发明之前 7层 TCP/IP 模型 没有明确的区分服务，接口，协议 产生在协议发明之后 4层","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"Go 启动过程","slug":"go_bootstrap","date":"2018-09-08T16:00:00.000Z","updated":"2018-09-13T13:02:05.661Z","comments":true,"path":"2018/09/09/go_bootstrap/","link":"","permalink":"http://phachon.github.io/2018/09/09/go_bootstrap/","excerpt":"通过查阅资料，了解 Go 语言的启动过程。 启动总体顺序 命令行参数解析 操作系统相关初始化 调度器初始化 创建 main.goroutine 运行 main 函数 命令行参数初始化主要是解析命令行参数并保存 操作系统相关初始化主要是确定操作系统的 CPU 核数，CPU 核数决定默认的了 P 的数量","text":"通过查阅资料，了解 Go 语言的启动过程。 启动总体顺序 命令行参数解析 操作系统相关初始化 调度器初始化 创建 main.goroutine 运行 main 函数 命令行参数初始化主要是解析命令行参数并保存 操作系统相关初始化主要是确定操作系统的 CPU 核数，CPU 核数决定默认的了 P 的数量 调度器初始化调度器的初始化时启动程序的核心 设置 M 的最大数量（10000） 内存相关初始化 M 的初始化 存储命令行参数和环境变量 解析 Debug 调试参数 初始化垃圾回收器 初始化 poll 时间 社会最大的 P 的数量，默认是 CPU 核数 main.goroutine 初始化 设置栈的最大值 启动后台监控 初始化 runtime.init 及 runtime 包 启动垃圾回收器 初始化 main.init 及用户或第三方引入的包 执行 main.main 函数执行入口函数，开始运行","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"并发服务器的实现方式","slug":"concurrrent_server","date":"2018-09-08T16:00:00.000Z","updated":"2018-09-22T02:24:42.207Z","comments":true,"path":"2018/09/09/concurrrent_server/","link":"","permalink":"http://phachon.github.io/2018/09/09/concurrrent_server/","excerpt":"","text":"并发服务器的实现方式一般有三种：多进程服务器，多线程服务器，多路复用服务器 多进程服务器实现原理：当父进程 accept 一个请求之后，立即 Fork 出一个子进程去处理请求。而父进程则继续循环等待 accept 接受到新的请求。没有请求的情况下，父进程处于阻塞状态。 创建套接字 绑定（bind）服务器端口 监听（listen）端口 受理（accept）连接请求 给获取到新的请求创建网络套接字传递(fork)给子进程 子进程处理连接 继续（accept）等待新的连接 子进程会复制父进程的所有资源，多个子进程之间相互独立，互不影响。 多进程服务器的优点 由操作系统进行调度，运行相对稳定健壮 通过操作系统可以方便的进行监控和管理 比较好的隔离性，每个进程相互独立，不影响主程序的稳定性。 充分利用多核 CPU , 实现并行处理 多进程服务器的缺点 进程的创建和销毁比较消耗资源，每个进程都独立加载完整的应用环境，内存消耗比较大。 CPU 消耗高，高并发下，进程之间频繁的进行调度切换，需要大量的内存操作 进程数量限制了并发处理数，使得 I/O 的并发处理能力比较低 多线程服务器通常在一个进程中可以包含若干个线程，当然一个进程中至少有一个线程，不然没有存在的意义。线程可以利用进程所拥有的资源，在引入线程的操作系统中，通常都是把进程作为分配资源的基本单位，而把线程作为独立运行和独立调度的基本单位，由于线程比进程更小，基本上不拥有系统资源，故对它的调度所付出的开销就会小得多，能更高效的提高系统多个程序间并发执行的程度。 多线程服务器的实现： 创建套接字 绑定（bind）服务器端口 监听（listen）端口 受理（accept）连接请求 服务器通过 accept 受理连接请求 每当有新连接时，创建新的线程来处理用户请求 处理完成后，销毁线程 继续（accept）接收新的连接请求 多线程服务器的优点 对内存消耗小，线程之间共享进程的堆内存和数据，每个线程的栈都比较小，不超过 1M CPU 上下文切换比较快 线程的切换开销远低于进程，I/O 的并发能力强 多线程服务器的缺点 不方便操作系统的管理 由于线程存在对资源的共享操作，一旦出现死锁和线程阻塞，使得影响整个应用的稳定性 多路复用服务器多路复用即 I/O 多路复用，是指内核一旦发现进程指定的一个或者多个 I/O 条件准备读取，它就通知该进程。I/O复用原理：让应用程序可以同时对多个I/O端口进行监控以判断其上的操作是否可以进行，达到时间复用的目的。 select 模型使用 select 函数时，可以将多个文件描述符集中到一起进行监视： 是否存在套接字接受数据 无需阻塞传输数据的套接字有哪些 哪些套接字发生了异常 利用 select 函数实现 I/O 复用服务器实现过程描述： 创建套接字 绑定（bind）服务器端口 监听（listen）端口 注册服务端套接字到 fd_set 变量 while 循环 调用 select 函数监听 fd_set 里的套接字 监听发生状态变化的（有接受数据的）网络套接字 首先发生变化的是否是验证服务端套接字，如果是，则说明有新的连接请求，accept 新的请求，并将客户端连接的套接字注册到 fd_set 变量中 如果发生变化不是服务端套接字，则说明是客户端连接套接字，则读取客户端数据 读取的数据是 EOF，则证明套接需要关闭套接字，并从 select 注册的套接字中删除该套接字 select 的几大缺点： 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大 同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大 select支持的文件描述符数量太小了，默认是1024 利用 poll 实现 I/O 复用服务器实现过程和 select 函数大致相同，区别在于 select 使用的结构是集合 fd_set 结构，poll 使用的结构是 pollsd 结构。 利用 epoll 实现 I/O 复用服务器基于 select 的 I/O 复用服务器，有比较明显的不合理： 每次调用 select 函数后针对所有文件描述符分循环 每次调用 select 函数都需要向该函数传递监视对象的信息（fd_set） 每次调用 select 函数时是向操作系统传递监视对象信息，那必然会发生系统调用，需要把 fd 集合从用户态拷贝到内核态。开销太大 Linux 下的 epoll 具有如下优点： 无需编写以监视状态变化为目的针对所有文件描述符的循环语句 调用对应于 select 函数的 epoll_wait 函数无需每次都传递监视对象信息 epoll 提供了三个函数： epoll_create：是创建一个 epoll 句柄 epoll_ctl：是注册要监听的事件类型 epoll_wait：则是等待事件的产生 实现过程描述： 创建套接字 绑定（bind）服务器端口 监听（listen）端口 epoll_create 创建 epoll 例程 epoll_ctl(add) 注册事件到 epoll 句柄 while 循环 调用 epoll_wait 函数监听套接字 监听发生状态变化的（有接受数据的）网络套接字 首先发生变化的是否是验证服务端套接字，如果是，则说明有新的连接请求，accept 新的请求，并调用 epoll_ctl 将客户端连接的套接字注册到 epoll 句柄 如果发生变化不是服务端套接字，则说明是客户端连接套接字，则读取客户端数据 读取的数据是 EOF，则证明套接需要关闭套接字，调用 epoll_ctl(del) 注册事件到 epoll 句柄 epoll 和 selectp/poll 最大的区别： epoll_ctl 函数，每次注册新的事件到 epoll 句柄时，会把所有的 fd 拷贝进内核，而不是在 epoll_wait 的时候重复拷贝。epoll 保证了每一个 fd 在整个过程中只会拷贝一次 epoll 的解决方案不像 select 或 poll 一样每次都把需要监听的套接字加入 fd 对应的设备等待队列中，而只在 epoll_ctl 时挂载一遍，并为每个 fd 设置一个回调函数，当设备就绪，唤醒等待队列的等待者时，就会调用这个函数，而这个毁掉函数就会把 fd 加入一个有序链表。 epoll_wait 的工作实际上就是在这个就绪的链表中查看有没有就绪的 fd。 总结","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"go 语言的并发机制","slug":"go_concurrent","date":"2018-09-02T16:00:00.000Z","updated":"2018-09-13T13:02:05.662Z","comments":true,"path":"2018/09/03/go_concurrent/","link":"","permalink":"http://phachon.github.io/2018/09/03/go_concurrent/","excerpt":"在操作系统的搭建的内核线程之上，go 语言搭建了一个特有的两极线程模型。首先来了解一下线程实现模型，然后再详细了解 go 语言实现的 线程实现模型线程的实现模型主要有三种：用户级线程模型、内核级线程模型、两极线程模型。它们之间的区别主要是线程与内核调度对象之间的的对应关系。内核调度象也就是内核线程。 用户级线程模型用户级线程模型是由用户级别的线程库来全权管理的。也就是说，用户级线程模型下的线程是往往是通过应用程序的线程库来创建、切换、销毁的。与操作系统内核的线程没有关系。操作系统内核的线程调度器也无法调度用户级线程模型创建的线程。内核线程调度器只能调度创建此线程的的应用程序的进程。一个进程对应多个用户级线程，所以这种线程模型又称为多对一（M:1）的线程模型, 如下图所示：","text":"在操作系统的搭建的内核线程之上，go 语言搭建了一个特有的两极线程模型。首先来了解一下线程实现模型，然后再详细了解 go 语言实现的 线程实现模型线程的实现模型主要有三种：用户级线程模型、内核级线程模型、两极线程模型。它们之间的区别主要是线程与内核调度对象之间的的对应关系。内核调度象也就是内核线程。 用户级线程模型用户级线程模型是由用户级别的线程库来全权管理的。也就是说，用户级线程模型下的线程是往往是通过应用程序的线程库来创建、切换、销毁的。与操作系统内核的线程没有关系。操作系统内核的线程调度器也无法调度用户级线程模型创建的线程。内核线程调度器只能调度创建此线程的的应用程序的进程。一个进程对应多个用户级线程，所以这种线程模型又称为多对一（M:1）的线程模型, 如下图所示： 优势 对线程的各种管理调度与内核无关。应用程序对线程的创建、终止、切换等操作不需要让CPU从用户态切换到内核态。速度方面比较有优势 由于不依赖内核，所以程序的一致性比较强 劣势 由于此模型下内核调度的最小单位是进程。如果线程阻塞，则整个进程被阻塞。 不能真正利用多核 CPU 来实现并发。进程中的多个线程无法被分配到多个 CPU 中去执行。 综上所述，由于缺陷明显，所以现在的操作系统一般不使用此种模型来实现线程 内核级线程模型和用户级线程相反，内核级线程是由内核来管理的，属于内核的一部分。应用程序对线程的创建、终止、切换等操作必须通过内核提供的系统调用来完成。进程中的每一个线程都与内核线程一一对应由此，也称为一对一（1：1）的线程模型。如下图所示： 优势 一对一的线程模型消除了多对一的线程模型的不能真正并发的弊端，线程的管理由内核管理和调度，内核可以在不同的时间片内让CPU运行不同的线程。 即使某一个线程收到阻塞，其他线程不受影响 劣势 创建线程和管理线程的成本加大，要经常去系统调用来管理线程，线程管理的时间耗费的时间相对比较大。 如果一个进程包含大量的线程，将会给内核的调度器带来非常大的负担，甚至会影响操作系统的整体性能。 消耗更多的内核资源 尽管内核级线程也有劣势，但是相比用户级线程的优势还是比较明显的。很多的现代的操作系统都是以内核级线程模型来实现线程的。包括 Linux 操作系统。需要注意的是，在使用内核级线程模型时，必须了解每个进程允许的线程的最大数目是多少。防止线程数过大造成操作系统性能下降甚至崩溃。 两极线程模型两极线程模型是根据用户级线程模型和内核级线程模型综合演变而来。可以说是取前两种模型之精华，去前两种模型之糟粕。在此模型下，一个进程可以与多个内核线程相关联。这与内核级线程相似。但与内核线程模型不同的是，进程中的线程并不与内核线程一一对应，这些应用程序线程可以映射到同一个已关联的内核线程上。 首先实现了两极线程模型的线程库会通过操作系统调用创建多个内核线程。然后，它会通过这些内核线程对应用程序线程进行调度。大多数的此类线程库都可以将这些应用程序线程动态的与内核线程相关联。在这种实现中，进程有着自己的内核线程池。可运行的用户线程由运行时库分派并标记为准备好执行的可用线程。操作系统选择用户线程并将它映射到线程池中的可用内核线程。多个用户线程可以分配给相同的内核线程。如下图所示： 优势 内核资源的消耗大大减少 线程管理操作的效率提高 劣势 由于此种模型的线程设计使得管理工作变得更加复杂 因为两极线程的复杂性，往往不会被操作系统所采用，但是，这样的模型却可以很好地在编程语言层面上实现并充分发挥作用。Go 语言的并发模型正是在该模型的基础上实现的。 Go 语言并发模型Go 的线程实现模型。有三个必知的核心元素。他们支撑起了模型的主要框架。 M （machine）一个 M 代表一个内核线程 P （processor）一个 P 代表一个 Go 代码片段所必须的资源。goroutine依赖于 P 进行调度，P 是真正的并行单元； G （goroutine）一个 G 代表一个 Go 代码片段。 简单来说，一个 G 的执行，需要 P 和 M 的支持。一个 M 在一个 P 关联之后就形成了一个有效的 G 的运行环境（内核线程 + 上下文环境）。 对应关系： M 与操作系统内核线程是一对一的关系。即一个 M 只能代表一个内核级线程。并且他们之间的关系一旦关联一般不可改变。 M 与 P 之间的关系也是一对一的关系。但是他们之间的关联是易变的。会根据实际的调度来确定哪个 P 和 M 关联。 P 与 G 之间的关系是一对多的关系。因为每个 P 中都有一个可运行的 G 队列。 M上面已经讲了，一个 M 代表一个内核线程。一般情况下，创建 M 的时机一般是由于没有足够的 M 来管理 P ，并运行 P 中的可执行队列中的 G 。除此之外，在运行时系统执行监控和垃圾回收的过程中也会导致新的 M 的创建。 M 的核心结构字段123456789type M struct &#123; g0 *g // 特殊的 goroutine, 系统启动时创建，执行一些运行时任务 msstartfn func() // M 的其实函数。其实就是编写 go 语句时携带的函数 curg *g // 当前 M 正在执行的 G 指针 p punittr // 当前 M 关联的 P nextp punittr // 当前 M 预关联的 P ，可以理解为提前关联 spinning bool // 当前 M 是否正在寻找可运行的 G lockedg *g // 运行时系统可以把一个 M 和 一个 G 锁定在一起。那么这个 G 只能由这个 M 运行。&#125; M 的生命周期 创建 M，M 在创建后加入全局的 M 列表中。起始函数和预关联的 P 都会被设置好。 运行时系统会为 M 专门创建一个新的内核线程并与之相关联。 初始化 M （栈空间，信号等） 开始执行起始函数（如果存在的话） 起始函数执行完成后，当前 M 会与预关联的 P 完成关联，并准备执行其他任务。M 会依次在多处寻找可运行的 G 。 单个 Go 程序的 M 的最大值是可以设置的，初始化调度器的时候，会对 M 最大数量初始化。最大值为 10000。也就是说最多有 10000 个内核级线程服务于当前的 Go。但是在真正的操作系统运行环境中，基本上很难达到如此的量级的线程共存。所以可以忽略 Go 本身对于线程数量的限制。也可以通过标准库代码包 runtime/debug 中的 SetMaxThreads 函数来限制 M 的最大值。 PP 是 G 能够在 M 中运行的桥梁，Go 的运行时系统会适时的让 P 与不同的 M 建立或断开连接，使得 P 中的那些 G 能够及时获得运行时机，就像是操作系统内核在 CPU 之上的适时切换不同的进程和线程的场景类似改变 P 的最大数量有两种方法： 调用函数 runtime.GOMAXPROCS 传入参数的方式 在 Go 程序运行前设置环境变量 GOMAXPROCS 的值 P 的最大值是 Go 程序并发规模的的限制。P 的数量即可运行的 G 的队列的数量。一个 G 被启动后，首先会被追加到某个 P 中的可运行 G 队列中，等待时机运行。在设置 P 的最大值的时候，会检查该值的有效性，当前，Go 目前还不能保证在数量比 256 更多的 P 同时存在的情形下 Go 仍能保持高效，因此，只要不大于 256，都是被认为是有效的值。一般情况下，P 设置为当前计算机的 CPU 核数。 G每个 G 代表一个 goroutine, 编程时，我们使用 go 语句只是提交了一个并发任务。而 Go 的运行时系统则会安装要求并发执行它。那么当执行 go 关键字的时候发生了什么呢？Go 编译器会把 go 语句变成对内部函数 newproc (runtime.proc.go) 的调用。 1234567func newproc(siz int32, fn *funcval) &#123; argp := add(unsafe.Pointer(&amp;fn), sys.PtrSize) pc := getcallerpc(unsafe.Pointer(&amp;siz)) systemstack(func() &#123; newproc1(fn, (*uint8)(argp), siz, 0, pc) &#125;)&#125; 真正执行的函数在 newproc1(), 有需要请自行看源码，执行顺序如下： 获得当前的 G 所在的 P，然后从空闲的 G 队列中取出一个 G 如果 1 取到则对这个 G 进行参数配置，否则新建一个G 将 G 加入 P 的可运行的 G 队列 调度器在 Go 语言中，调度器的主要调度对象就是 M, P, G 的实例。调度器在调度过程中需要依赖全局的调度对象的容器。简单来说，为了方便调度，调度器会对 M,P,G 的实例存储在容器中。调度器的容器包括： 调度器的空闲 M 列表：存放空闲的 M 的单向链表 调度器的空闲 P 列表：存放空闲的 P 的单向链表 调度器的可运行 G 队列：存放可运行 G 的队列 调度器的自由 G 列表：存放自由的 G 的单向链表 调度器有自己的数据结构，形成此结构的主要目的是更加方便的管理和调度各个核心元素的实例。 基本结构goroutinegoroutine 的核心理念是： 1不要以共享内存的方式来通信。应该以通信作为手段来共享内存","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"Go 语言操作 mysql 建表问题的解决办法","slug":"go-mysql-create-table","date":"2018-02-04T16:00:00.000Z","updated":"2018-09-13T13:02:05.661Z","comments":true,"path":"2018/02/05/go-mysql-create-table/","link":"","permalink":"http://phachon.github.io/2018/02/05/go-mysql-create-table/","excerpt":"问题开发中需要利用 go 读取 sql 文件自动创建表。 table.sql 文件内容如下123456DROP TABLE IF EXISTS `user`;CREATE TABLE `user` ( `user_id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;主键ID&apos;, `name` varchar(30) NOT NULL COMMENT &apos;姓名&apos;, PRIMARY KEY (`user_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;用户表&apos;;","text":"问题开发中需要利用 go 读取 sql 文件自动创建表。 table.sql 文件内容如下123456DROP TABLE IF EXISTS `user`;CREATE TABLE `user` ( `user_id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;主键ID&apos;, `name` varchar(30) NOT NULL COMMENT &apos;姓名&apos;, PRIMARY KEY (`user_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;用户表&apos;; go 代码如下：1234567891011121314151617181920212223func createTable() (err error) &#123; host := &quot;127.0.0.1&quot; port := &quot;3306&quot; user := &quot;root&quot; pass := &quot;admin&quot; name := &quot;test&quot; sqlBytes, err = ioutil.ReadFile(&quot;docs/databases/table.sql&quot;); if err != nil &#123; return &#125; sqlTable := string(sqlBytes); fmt.Println(sqlTable) db, err := sql.Open(&quot;mysql&quot;, user+&quot;:&quot;+pass+&quot;@tcp(&quot;+host+&quot;:&quot;+port+&quot;)/&quot;+name+&quot;?charset=utf8&quot;) if err != nil &#123; return &#125; defer db.Close() _, err = db.Exec(sqlTable) if err != nil &#123; return &#125; return nil&#125; 执行，出错：12Error 1064: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &apos;CREATE TABLE `user` (`user_id` int(11) NOT NULL AUTO_INCREMENT COMMEN&apos; at line 1 刚开始是以为 sql 语句本身有问题，所以将 sql 语句直接粘贴到 mysql 命令行执行，成功。所以不是 sql 语句的问题。 查找资料才知道原因是 mysql 默认是不能在一个语句中同时执行两条 sql 语句，把 drop table 和 create table 拆开。 解决办法 将 多条 sql 语句拆开，每个语句单独执行 db.Exec() 查看 go-sql-driver 的文档，发现可以支持一条语句多条 sql 执行。修改代码如下1db, err := sql.Open(&quot;mysql&quot;, user+&quot;:&quot;+pass+&quot;@tcp(&quot;+host+&quot;:&quot;+port+&quot;)/&quot;+name+&quot;?charset=utf8&amp;multiStatements=true&quot;) 增加了 &amp;multiStatements=true 参数","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/tags/Go/"},{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/tags/Mysql/"}]},{"title":"PHPUnit windows 下的安装","slug":"PHPUnit-install-windows","date":"2017-10-19T16:00:00.000Z","updated":"2018-09-13T13:02:05.659Z","comments":true,"path":"2017/10/20/PHPUnit-install-windows/","link":"","permalink":"http://phachon.github.io/2017/10/20/PHPUnit-install-windows/","excerpt":"本篇文章介绍一下 PHPUnit 在 windows 下的安装和配置 准备 php 版本 php5.4.45 phpunit 版本 phpunit4.8.24 操作系统：windows 7 (32) php 安装（这里不再详细讲解） phpunit 下载地址：https://phpunit.de/ 下载到文件 phpunit-4.8.24.phar","text":"本篇文章介绍一下 PHPUnit 在 windows 下的安装和配置 准备 php 版本 php5.4.45 phpunit 版本 phpunit4.8.24 操作系统：windows 7 (32) php 安装（这里不再详细讲解） phpunit 下载地址：https://phpunit.de/ 下载到文件 phpunit-4.8.24.phar 安装 将下载的 phpunit-4.8.24.phar 文件保存保存为phar到你自己设定的目录，如我的目录是D：\\server\\phpunit 下。 配置 path 环境变量；计算机右击属性—&gt;高级系统设置—&gt;环境变量–&gt; 在系统变量下找到 path 一栏，选中，编辑。添加 phpunit 路径;D:\\server\\phpunit 到最后。注意 ; 不要忘记。 按快捷键Win + R ，输入cmd并回车。打开 cmd 命令窗口，进入phpunit 的文件目录。D：\\server\\phpunit 输入 echo @php “%~dp0phpunit.phar” %* &gt; phpunit.cmd 接着输入phpunit –version 并回车显示如下 1PHPUnit 4.8.24 by Sebastian Bergmann and contributors 表示安装成功。（如果有误，输入exit 并回车，重新来一遍） 注意：如果失败，请检查你的 php path 变量是否配置 基本命令 –log-tap 生成TAP格式的日志文件 –log-dbus 使用DBUS记录测试的执行情况 –log-json 生成JSON格式的日志文件 –coverage-html 生成html格式的代码覆盖报告请注意这个功能只能在tokenizer和Xdebug安装后才能使用 –coverage-clover 生成xml格式的代码覆盖报告请注意这个功能只能在tokenizer和Xdebug安装后才能使用 –testdox-html and –testdox-text 生成记录已运行测试的html或者纯文本格式的文件文档 –filter 只运行名字符合参数规定的格式的测试，参数可以是一个测试的名字或者一个匹配多个测试名字的正则表达式 –group 只运行规定的测试组，一个测试可以使用@group注释来分组 @author注视是一个和@group关联的注释标签，用来根据作者来过滤测试 –exclude-group 只包含规定的多个测试组，一个测试可以使用@group注释来分组 –list-groups 列出可用的测试组 –loader 定义使用PHPUnit_Runner_TestSuiteLoader的接口 –repeat 根据定义的数字重复运行测试 –tap 使用Test Anything Protocol格式报告测试进程 –testdox 使用agile documentation格式报告测试进程 –colors 在输出结果中使用颜色 –stderr 使用STDERR替代STDOUT输出结果 –stop-on-error 在遇到第一个错误时停止执行 –stop-on-failure 在遇到第一个失败时停止执行 –stop-on-skipped 在遇到第一个跳过的测试时停止执行 –stop-on-incomplete 在遇到第一个未完成的测试时停止执行 –strict 当一个测试没有定义任何断言时将其标记为未完成的测试 –verbose 输出例如未完成的测试的名字，跳过的测试的名字 –wait 在每个测试开始之前等待用户按键，这个在你一个保持打开的窗口中运行很长的测试时很有帮助 –skeleton-class 从一个测试类中生成一个概要测试类 –skeleton-test 在Unit.php内为类Unit生成一个概要测试类UnitTest –process-isolation 在多个php进程中运行所有测试 –no-globals-backup 不备份和还原$GLOBALS变量 –static-backup 备份和还原用户定义的类中的静态变量 –syntax-check 对测试的代码文件开启语法检查 –bootstrap 定义测试前运行的bootstrap的php文件的路径 –configuration, -c 从xml文件中读取配置，增加-c参数看更多的内容如果phpunit.xml或phpunit.xml.dist(根据这个模式)在当前的目录中存在且–configuration参数没有使用的时候，配置信息会被自动读取 –no-configuration 自动跳过当前目录的phpunit.xml和phpunit.xml.dist配置文件 –include-path 在php的include_path增加路径 -d 定义php的配置属性 –debug 输出调试信息如测试的名称及该测试什么时候开始执行 提示当测试代码中含有php语法错误的时候，测试器会退出且不会打印任何错误信息，standard test suite loader可选择性检查测试文件源代码的PHP语法错误，但是不会检查测试文件中引入的其他的代码文件的语法错误","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"},{"name":"PHPUnit","slug":"PHPUnit","permalink":"http://phachon.github.io/tags/PHPUnit/"},{"name":"Windows","slug":"Windows","permalink":"http://phachon.github.io/tags/Windows/"}]},{"title":"PHPUnit 学习实例代码","slug":"PHPUnit-Lean1","date":"2017-10-19T16:00:00.000Z","updated":"2018-09-13T13:02:05.659Z","comments":true,"path":"2017/10/20/PHPUnit-Lean1/","link":"","permalink":"http://phachon.github.io/2017/10/20/PHPUnit-Lean1/","excerpt":"PHPUnit 基本用法+实例详解上一篇文章介绍了 PHPUnit 在 windows 的安装和配置。今天我们来介绍一下 PHPUnit 如何编写一些基本的测试用例。我也是在最近才开始慢慢使用的 PHPUnit , 用不足之处，欢迎指正。 编写规范 测试类一般以***Test 命名； 该类必须继承 PHPUnit_Framework_TestCase 类； 类里的测试用例方法一般以test开头，当然也可以通过@test注释来定义一个名字不为test开头的方法为测试方法； 测试方法中需要使用断言方法来断言实际传入的参数与期望的参数是否一致来达到测试的目的；","text":"PHPUnit 基本用法+实例详解上一篇文章介绍了 PHPUnit 在 windows 的安装和配置。今天我们来介绍一下 PHPUnit 如何编写一些基本的测试用例。我也是在最近才开始慢慢使用的 PHPUnit , 用不足之处，欢迎指正。 编写规范 测试类一般以***Test 命名； 该类必须继承 PHPUnit_Framework_TestCase 类； 类里的测试用例方法一般以test开头，当然也可以通过@test注释来定义一个名字不为test开头的方法为测试方法； 测试方法中需要使用断言方法来断言实际传入的参数与期望的参数是否一致来达到测试的目的； 测试用例 基本的demo 定义一个类 DemoTest 并保存到 DemoTest.php 文件中 123456789101112131415161718192021222324252627282930313233343536&lt;?php/** * phpunit test demo * @author phachon@163.com */class DemoTest extends PHPUnit_Framework_TestCase &#123; /** * test */ public function testPushAndPop() &#123; $stack = array (); //断言 $stack 的长度为0 $this-&gt;assertEquals(0, count($stack)); array_push($stack, 'foo'); //断言 $stack 的长度为 1 $this-&gt;assertEquals(1, count($stack)); //断言 $stack 的最后一个值为foo $this-&gt;assertEquals('foo', $stack[count($stack)-1]); //断言 $stack 出栈的值为 foo $this-&gt;assertEquals('foo', array_pop($stack)); //断言 $stack 的长度为 0 $this-&gt;assertEquals(0, count($stack)); &#125; /** * 定义test标签来声明是测试方法 * @test */ public function indexEquals() &#123; $stack = array (0,1,2,3,4); //断言 $stack 索引 0 的值为2 $this-&gt;assertEquals(2, $stack[0]); &#125;&#125; 上面的代码中定义了两种测试用例的方法，一种是开头为test, 一种是定义@test标签；两种都可以。然后运行测试这个类；打开命令窗口，进入该代码保存的文件目录输入:phpunit DemoTest.php运行结果为： 1234567Time:825 ms, Memory: 8.25MbThere was 1 failure:1) DemoTest::indexEqualsFailed asserting that 0 matches expected 2.D:\\server\\apache\\htdocs\\my_php_code\\phpunit\\stack\\DemoTest.php:32FAILURES!Tests: 2, Assertions: 6, Failures: 1. 解释一下：最上面的是一些耗时，内存消耗的多少。往下看测试结果说有一个错误，也就是测试未通过，在文件的32行。32行的意思是断言这个数组中索引为0的值为2，显然不是，这里我故意写错，所以测试失败。如果改为0则会显示OK;最后是显示2个测试用例，6个断言，其中一个失败。 方法依赖关系 在测试类中，测试用例方法可以有依赖关系。通过依赖关系可以传一些参数到方法中；因为默认的测试用例方法是不能有参数的。定义一个FunTest 类保存到文件中 1234567891011121314151617181920212223242526272829303132333435&lt;?php/** * 测试方法依赖关系 * @author phachon@163.com */class FuncTest extends PHPUnit_Framework_TestCase &#123; public function testEmpty() &#123; $stack = array (); $this-&gt;assertEmpty($stack); return $stack; &#125; /** * depends 方法用来表示依赖的方法名 * @depends testEmpty * @param array $stack * @return array */ public function testPush(array $stack) &#123; array_push($stack, 'foo'); $this-&gt;assertEquals('foo', $stack[count($stack)-1]); return $stack; &#125; /** * @depends testPush * @param array $stack */ public function testPop(array $stack) &#123; $this-&gt;assertEquals('foo', array_pop($stack)); $this-&gt;assertEmpty($stack); &#125;&#125; 标签@depends是表示依赖关系，上面的代码中testPop()依赖testPush(),testPush()依赖testEmpty(), 所以当testEmpty()测试通过后返回的变量可以作为testPush(array $stack)的参数。同理，testPop()也是一样。运行结果如下： 12Time: 726 ms, Memory: 8.25MbOK (3 tests, 4 assertions) 测试通过 测试非依赖关系的方法传入参数 如果非依赖关系的方法，默认是不能有参数的，这个时候怎么样才能传参，PHPUnit 提供给了一个标签，@dataProvider定义一个DataTest类保存到文件中 12345678910111213141516171819202122232425262728293031323334&lt;?php/** * 测试非依赖关系的方法传入参数 * 方法提供者 * @author phachon@163.com */class DataTest extends PHPUnit_Framework_TestCase &#123; /** * dataProvider 标签用来提供数据的方法名 * @dataProvider add_provider */ public function testAdd($a, $b, $c) &#123; //断言 a + b = c $this-&gt;assertEquals($c, $a + $b); &#125; /** * 数据提供者的方法 * 格式： * return array( * array(参数1,参数2,参数3,参数4,参数N), * array(参数1,参数2,参数3,参数4,参数N), * ); */ public function add_provider() &#123; return array ( array (0, 0, 0), array (0, 1, 1), array (1, 0, 1), array (1, 1, 2), ); &#125;&#125; 看上面代码应该就能明白。直接运行phpunit DataTest.php运行结果如下： 12Time: 379 ms, Memory: 8.25MbOK (3 tests, 4 assertions) 数据提供者方法和依赖关系的限制 这个听起来有点绕口，意思是如果方法依赖和方法提供者同时使用的话，是有限制的。说半天我估计还是一塌糊涂，不解释，直接看代码定义一个 Data2Test 类保存到文件 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?php/** * 数据提供者方法和依赖关系的限制 * * 当一个测试方法依赖于另外一个使用data providers测试方法时, * 这个测试方法将会在它依赖的方法至少测试成功一次后运行, * 同时使用data providers的测试方法的执行的结果不能传入一个依赖它的测试方法中 * @author phachon@163.com */class Data2Test extends PHPUnit_Framework_TestCase &#123; public function testA() &#123; return 78; &#125; /** * @dataProvider add_provider * @depends testB */ public function testB($a, $b, $c) &#123; $this-&gt;assertEquals($c, $a + $b); return $a; &#125; /** * @depneds testB */ public function testC($a) &#123; var_dump($a); &#125; public function add_provider() &#123; return array ( array (0, 0, 0), array (0, 1, 1), array (1, 0, 1), array (1, 1, 2), ); &#125;&#125; 解释一下：testB 依赖于 testA (testA 使用了dataProvider 提供数据)如果 add_provider 提供的数据至少有一次是成功的，则在成功一次后运行 testC如果 add_provider 提供的数据没有一次是成功的，则 testC 一次也不会执行但是 testC 执行的结果永远是 null, 因为 $a 是通过 dataProvider 提供的。不能传入依赖它的测试方法中好像还是不太明白，反正我是尽力了。慢慢理解吧。 通过构造迭代器来为方法提供数据 通过标签 @dataProvider 来直接返回数据作为数据提供者，PHPUnit 也可以通过返回构造器对象来提供数据。上代码新建 IteratorTest.php 文件 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?php/** * 通过构造迭代器来为方法提供数据 * @author phachon@163.com */class myIterator implements Iterator &#123; private $_position = 0; private $_array = array ( array (0, 0, 0), array (0, 1, 1), array (1, 0, 1), array (1, 1, 2) ); public function current() &#123; echo 0; return $this-&gt;_array[$this-&gt;_position]; &#125; public function key() &#123; echo 1; return $this-&gt;_position; &#125; public function next() &#123; echo 2; ++$this-&gt;_position; &#125; public function valid() &#123; echo 3; return isset($this-&gt;_array[$this-&gt;_position]); &#125; public function rewind() &#123; echo 4; return $this-&gt;_position = 0; &#125;&#125; 123456789101112131415161718/** * 测试类 */class IteratorTest extends PHPUnit_Framework_TestCase &#123; /** * @dataProvider add_provider */ public function testAdd($a, $b, $c) &#123; $this-&gt;assertEquals($c, $a + $b); &#125; public function add_provider() &#123; return new myIterator(); &#125;&#125; 先定义了一个构造器，然后返回这个构造器对象，同样也能提供数据。运行 phpunit IteratorTest.php运行结果如下： 12Time: 408 ms, Memory: 8.25MbOK (4 tests, 4 assertions) 异常测试 有时候我们希望能够抛出我们所期待的异常。这里有三种方法来测试异常，上代码定义 ThrowTest 类保存到文件 123456789101112131415161718192021222324252627282930313233343536&lt;?php/** * 测试异常 * 三种方法 * @author phachon@163.com */class ThrowTest extends PHPUnit_Framework_TestCase &#123; /** * 1.注释法: expectedException 期待的异常 * @expectedExeption My_Exception */ public function testException1() &#123; &#125; /** * 2.设定法：$this-&gt;setExpectedException 期待的异常 */ public function testException2() &#123; $this-&gt;setExpectedException('My_Exception'); &#125; /** * 3.捕获法：try catch */ public function testException3() &#123; try &#123; //代码 &#125; catch (My_Exception $e) &#123; //捕获到异常测试通过，否则失败 return ; &#125; $this-&gt;fail('一个期望的异常没有被捕获'); &#125;&#125; 代码应该很明白了，不用解释了。 错误测试 有时候代码会发生错误，比如某个php文件找不到，文件不可读，php 文件加载失败等。这个时候我们也能进行测试，是否发生错误；PHPUnit 会把错误直接转化为异常PHPUnit_Framework_Error并抛出；我们要做到的是捕获这个异常。上代码。定义 ErrorTest 类保存到文件中 12345678910111213141516&lt;?php/** * 错误测试 * phpunit 会把错误直接转化为异常PHPUnit_Framework_Error并抛出 */class ErrorTest extends PHPUnit_Framework_TestCase &#123; /** * 期待捕获 PHPUnit_Framework_Error 的异常 * @expectedException PHPUnit_Framework_Error */ public function testError() &#123; //如果文件不存在就会抛出异常，我们需要捕获异常 include '../test.php'; &#125;&#125; 测试显示OK,则证明已经捕获。 对输出进行测试 有时候我们需要对程序的指定输出进行测试。比如echo 还是 print() 指定的值是否正确。定义类 OutputTest 类保存到文件 1234567891011121314151617&lt;?php/** * 输出测试 * @author phachon@163.com */class OutputTest extends PHPUnit_Framework_TestCase &#123; public function testExpectFooActualFoo() &#123; $this-&gt;expectOutputString('foo'); print 'foo'; &#125; public function testExpectBarActualBaz() &#123; $this-&gt;expectOutputString('bar'); print 'baz'; &#125;&#125; 注意: 在严格模式下，本身产生输出的测试将会失败。 基镜（fixture） PHPUnit 支持共享建立基境的代码。在运行某个测试方法前，会调用一个名叫 setUp() 的模板方法。setUp() 是创建测试所用对象的地方。当测试方法运行结束后，不管是成功还是失败，都会调用另外一个名叫 tearDown() 的模板方法。tearDown() 是清理测试所用对象的地方。 12345678910111213141516171819202122232425&lt;?phpclass FixTureTest extends PHPUnit_Framework_TestCase &#123; protected $stack; protected function setUp() &#123; $this-&gt;stack = array(); &#125; public function testEmpty() &#123; $this-&gt;assertTrue(empty($this-&gt;stack)); &#125; public function testPush() &#123; array_push($this-&gt;stack, 'foo'); $this-&gt;assertEquals('foo', $this-&gt;stack[count($this-&gt;stack)-1]); $this-&gt;assertFalse(empty($this-&gt;stack)); &#125; public function testPop() &#123; array_push($this-&gt;stack, 'foo'); $this-&gt;assertEquals('foo', array_pop($this-&gt;stack)); $this-&gt;assertTrue(empty($this-&gt;stack)); &#125;&#125; 以上是PHPUnit 官方的一个代码示例。测试类的每个测试方法都会运行一次 setUp() 和 tearDown() 模板方法（同时，每个测试方法都是在一个全新的测试类实例上运行的）。另外，setUpBeforeClass() 与 tearDownAfterClass() 模板方法将分别在测试用例类的第一个测试运行之前和测试用例类的最后一个测试运行之后调用。 setUp() 多 tearDown() 少理论上说，setUp() 和 tearDown() 是精确对称的，但是实践中并非如此。实际上，只有在 setUp() 中分配了诸如文件或套接字之类的外部资源时才需要实现 tearDown() 。如果 setUp() 中只创建纯 PHP 对象，通常可以略过 tearDown()。不过，如果在 setUp() 中创建了大量对象，你可能想要在 tearDown() 中 unset() 指向这些对象的变量，这样它们就可以被垃圾回收机制回收掉。对测试用例对象的垃圾回收动作则是不可预知的。 —PHPUnit 官方网站 总结好了，今天大概就先介绍这些，已经可以大概写一些测试用例了。当然还有更高级的测试使用方法。现在为什么不讲呢，因为我也不会。。","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"},{"name":"PHPUnit","slug":"PHPUnit","permalink":"http://phachon.github.io/tags/PHPUnit/"}]},{"title":"Go 获取文件信息方法","slug":"go-fileinfo","date":"2017-10-09T16:00:00.000Z","updated":"2018-09-13T13:02:05.661Z","comments":true,"path":"2017/10/10/go-fileinfo/","link":"","permalink":"http://phachon.github.io/2017/10/10/go-fileinfo/","excerpt":"最近一直在写 go 语言，总结下go获取文件信息的方法 获取文件修改时间1234fileInfo, _ := os.Stat(&quot;test.log&quot;)//修改时间modTime := fileInfo.ModTime()fmt.Println(modTime)","text":"最近一直在写 go 语言，总结下go获取文件信息的方法 获取文件修改时间1234fileInfo, _ := os.Stat(&quot;test.log&quot;)//修改时间modTime := fileInfo.ModTime()fmt.Println(modTime) 判断文件是否存在1234_, err := os.Stat(&quot;test.log&quot;)if(os.IsNotExist(err)) &#123; fmt.Println(&quot;file not exist!&quot;)&#125; 文件是否是目录1234fileInfo, _ := os.Stat(&quot;test.log&quot;)//是否是目录isDir := fileInfo.IsDir()fmt.Println(isDir) 文件权限1234fileInfo, _ := os.Stat(&quot;test.log&quot;)//权限mode := fileInfo.Mode()fmt.Println(mode) 获取文件名1234fileInfo, _ := os.Stat(&quot;test.log&quot;)//文件名filename:= fileInfo.Name()fmt.Println(filename) 获取文件大小1234fileInfo, _ := os.Stat(&quot;test.log&quot;)//文件大小filesize:= fileInfo.Size()fmt.Println(filesize)//返回的是字节 获取文件创建时间文件的创建时间并没有直接的方法返回，翻看源代码才知道如何获取 12345fileInfo, _ := os.Stat(&quot;test.log&quot;)fileSys := fileInfo.Sys().(*syscall.Win32FileAttributeData)nanoseconds := fileSys.CreationTime.Nanoseconds() // 返回的是纳秒createTime := nanoseconds/1e9 //秒fmt.Println(createTime) 文件最后写入时间12345fileInfo, _ := os.Stat(&quot;test.log&quot;)fileSys := fileInfo.Sys().(*syscall.Win32FileAttributeData)nanoseconds := fileSys.LastWriteTime.Nanoseconds() // 返回的是纳秒lastWriteTime := nanoseconds/1e9 //秒fmt.Println(lastWriteTime) 文件最后访问时间12345fileInfo, _ := os.Stat(&quot;test.log&quot;)fileSys := fileInfo.Sys().(*syscall.Win32FileAttributeData)nanoseconds := fileSys.LastAccessTime.Nanoseconds() // 返回的是纳秒lastAccessTime:= nanoseconds/1e9 //秒fmt.Println(lastAccessTime) 文件属性1234fileInfo, _ := os.Stat(&quot;test.log&quot;)fileSys := fileInfo.Sys().(*syscall.Win32FileAttributeData)fileAttributes:= fileSys.FileAttributesfmt.Println(fileAttributes) 介绍一个我用 go 写的日志管理包，地址： https://github.com/phachon/go-logger","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/tags/Go/"}]},{"title":"Bootstrap html后台模板总结","slug":"bootstrap-html","date":"2017-09-12T16:00:00.000Z","updated":"2018-09-13T13:02:05.659Z","comments":true,"path":"2017/09/13/bootstrap-html/","link":"","permalink":"http://phachon.github.io/2017/09/13/bootstrap-html/","excerpt":"","text":"总结的一些模板在个人的 github 地址，有需要的欢迎下载或 forkhttps://github.com/phachon/html-templates","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"Bootstrap","slug":"Bootstrap","permalink":"http://phachon.github.io/tags/Bootstrap/"},{"name":"Html","slug":"Html","permalink":"http://phachon.github.io/tags/Html/"}]},{"title":"后端知识点总结","slug":"knowledage","date":"2017-09-04T16:00:00.000Z","updated":"2018-09-21T13:42:32.497Z","comments":true,"path":"2017/09/05/knowledage/","link":"","permalink":"http://phachon.github.io/2017/09/05/knowledage/","excerpt":"","text":"数据结构 顺序表 链表 单向链表 双向链表 循环链表 队列 循环队列 链队列 栈 顺序栈 链栈 集合 树 二叉树 二叉树遍历 二叉查找树 平衡二叉树 红黑树 B 树 B 树的应用 LSM 树 算法 常见面试算法 算法 常被问到的算法题 面试算法题 剑指 OFFER 排序 各种排序算法复杂度分析 排序算法 十大经典的排序算法 查找 二分查找 插值查找 斐波那契查找 二叉查找树查找 哈希查找 过滤 大数据处理-Bitmap 布隆过滤器 基于 Redis 的 Bitmap 数据结构 网络爬虫：URL去重策略之布隆过滤器(BloomFilter)的使用 字符串匹配 KMP 字符串匹配 图遍历 深度优先遍历和广度优先遍历 贪心算法 《算法：贪婪算法基础》 《常见算法及问题场景——贪心算法》 一致性哈希 一致性哈希在Redis集群中的应用 网络知识 七层协议 TCP TCP 协议 TCP 三次握手 TCP中11种状态 TCP/IP/UDP协议详解 TCP/IP网络协议栈 TCP滑动窗口详解 TCP 知识点总结 TCP面试题集 UDP UDP 协议总结 KDP KCP 原理及源码解析 HTTP Http 协议详细讲解 Http1.0 和 Http1.1区别 Http2.0 原理详细分析 Http2.0 二进制帧 Session 和 Cookie 理解 Session 和 Cookie机制 跨域问题 跨域问题2 HTTPS Https 通俗了解 HTTPS协议详解(一)：HTTPS基础知识 HTTPS协议详解(二)：TLS/SSL工作原理 HTTPS协议详解(三)：PKI 体系 HTTPS协议详解(四)：TLS/SSL握手过程 HTTPS协议详解(五)：HTTPS性能与优化 进程线程协程 进程、线程、协程之概念理解 进程 进程的概念 进程间的同步机制 僵尸进程 线程 线程的基本概念 线程的三种实现方式 进程和线程的区别和联系 协程 协程的历史，现在和未来 以goroutine为例看协程的相关概念 PHP中协程的使用 内存分配 TCMalloc介绍 图解TCMalloc 内存优化总结 Linux命令 50个最常用的命令 Tcpdump使用抓包总结 中间件MySQL 学习MySQL优化原理，这一篇就够了 数据库优化 MySQL 数据库索引优化项目实战 mysql面试 mysql面试集锦 索引区别 数据库优化 Redis Redis总结 Redis底层原理 Redis 实现分布式锁 PHP Redis实现分布式锁 为什么 Redis 是单线程的 RabbitMQ RabbitMQ基础知识详解 RabbitMQ概念总结 深入了解RabbitMQ Nginx Nginx原理和优化 Nginx基础配置详解 Nginx基本学习 Apache 浅析 Apache 工作原理 Apache运行机制剖析 Nginx与Apache的对比及优缺点 Memcache 基本使用 深入理解 memcache 原理 Redis和Memcache区别，优缺点对比 Memcached实现机制 Sphinx Sphinx 的介绍和原理探索 Sphinx 在网站架构中的应用 ELK ELK多种架构及优势 Go语言基础 常见知识点 笔试网站 make和new区别 golang中的引用类型 高级 Golang适合高并发场景的原因分析 内存分配 内存分配与管理 内存管理 内存管理和垃圾回收 启动过程 go语言启动过程 并发机制 go语言并发机制 go 调度器 golang并发原理分析 理解 goroutine 的并发 Goroutine调度机制 Goroutine并发调度模型深度解析之手撸一个协程池 也谈goroutine调度器 channel channel的底层实现 深入理解 interface 其他 fasthhtp 的优化 PHP 基本知识点总结 综合 知识回顾 设计模式 23中设计模式深入理解 项目总结实现短网址项目https://www.jianshu.com/p/43eea66a2235https://www.cnblogs.com/lovekingly/p/5505308.htmlhttps://www.jb51.net/article/136554.htmhttps://www.cnblogs.com/flying1819/articles/8832640.html","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"火狐浏览器下刷新不清除表单问题","slug":"firefox-input","date":"2016-12-29T16:00:00.000Z","updated":"2018-09-13T13:02:05.661Z","comments":true,"path":"2016/12/30/firefox-input/","link":"","permalink":"http://phachon.github.io/2016/12/30/firefox-input/","excerpt":"问题js 控制表单重新刷新 12location.href = url;location.reload(); 测试时发现谷歌，360均正常，但是在火狐浏览器，刷新完之后，表单的数据还在，并没有清除，刚开始以为是浏览器的设置问题。查找资料后找到一些解决办法","text":"问题js 控制表单重新刷新 12location.href = url;location.reload(); 测试时发现谷歌，360均正常，但是在火狐浏览器，刷新完之后，表单的数据还在，并没有清除，刚开始以为是浏览器的设置问题。查找资料后找到一些解决办法 解决form 表单加参数 1&lt;form method=&quot;post&quot; autocomplete=&quot;off&quot; action=&quot;&quot;&gt; 1autocomplete=&quot;off&quot; 加了之后火狐刷新不再携带原始数据,清空表单 ok，测试通过，完美解决","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"Html","slug":"Html","permalink":"http://phachon.github.io/tags/Html/"},{"name":"FireFox","slug":"FireFox","permalink":"http://phachon.github.io/tags/FireFox/"},{"name":"javascript","slug":"javascript","permalink":"http://phachon.github.io/tags/javascript/"}]},{"title":"一个基于 node.js 搭建的web聊天系统","slug":"phaChat","date":"2016-10-10T16:00:00.000Z","updated":"2018-09-13T13:02:05.664Z","comments":true,"path":"2016/10/11/phaChat/","link":"","permalink":"http://phachon.github.io/2016/10/11/phaChat/","excerpt":"简介 一个简单的 web 聊天室, 采用 node.js 编写，基于 express + mysql + socket 实现的在线多人web 聊天系统，包括用户的登陆注册，用户的个人信息修改,目的是为了更加深入学习了解 node.js 和 websocket 技术，给初学者一个练习的小项目。有兴趣的同学可以继续完善（用户的头像上传，创建聊天群，消息保存等）","text":"简介 一个简单的 web 聊天室, 采用 node.js 编写，基于 express + mysql + socket 实现的在线多人web 聊天系统，包括用户的登陆注册，用户的个人信息修改,目的是为了更加深入学习了解 node.js 和 websocket 技术，给初学者一个练习的小项目。有兴趣的同学可以继续完善（用户的头像上传，创建聊天群，消息保存等） Install 安装 环境npm 3.node v6.express 4.3.mysql 5.5.redis 2.8.* 使用 进入根目录，phaChat npm install npm start //开启聊天室客户端 node server //开启聊天室服务端 浏览器输入 http://127.0.0.1:3000/chat/index, 界面效果注册 登录 聊天室 继续扩展 创建聊天室 用户修改头像 发送表情 model层优化 项目地址https://github.com/phachon/phaChat","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/tags/Mysql/"},{"name":"Node","slug":"Node","permalink":"http://phachon.github.io/tags/Node/"},{"name":"Express","slug":"Express","permalink":"http://phachon.github.io/tags/Express/"},{"name":"WebSocket","slug":"WebSocket","permalink":"http://phachon.github.io/tags/WebSocket/"}]},{"title":"ELK 实时日志分析系统平台的学习与使用","slug":"elk-install","date":"2016-09-21T16:00:00.000Z","updated":"2018-09-13T13:02:05.660Z","comments":true,"path":"2016/09/22/elk-install/","link":"","permalink":"http://phachon.github.io/2016/09/22/elk-install/","excerpt":"简介工作工程中，不论是开发还是运维，都会遇到各种各样的日志，主要包括系统日志、应用程序日志和安全日志，对于开发人员来说，查看日志，可以实时查看程序的运行错误，以及性能分析，通常，一个大中型的应用程序会被部署到多台服务器，那日志文件也会分散到不同的机器上，这样查看日志难道要一台一台去查看？显然是太麻烦了，开源的日志分析系统 ELK 完美的解决了这个问题。ELK 并不是一个独立的系统，她是由 ElasticSearch、Logstash、Kibana 三个开源的工具组成。 ElasticSearchElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。 LogstashLogstash 是一个开源的日志分析、收集工具，并将日志存储以供以后使用。 KibanaKibana 是一个为 Logstash 和 ElasticSearch 提供的日志分析的 Web 接口。可使用它对日志进行高效的搜索、可视化、分析等各种操作。","text":"简介工作工程中，不论是开发还是运维，都会遇到各种各样的日志，主要包括系统日志、应用程序日志和安全日志，对于开发人员来说，查看日志，可以实时查看程序的运行错误，以及性能分析，通常，一个大中型的应用程序会被部署到多台服务器，那日志文件也会分散到不同的机器上，这样查看日志难道要一台一台去查看？显然是太麻烦了，开源的日志分析系统 ELK 完美的解决了这个问题。ELK 并不是一个独立的系统，她是由 ElasticSearch、Logstash、Kibana 三个开源的工具组成。 ElasticSearchElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。 LogstashLogstash 是一个开源的日志分析、收集工具，并将日志存储以供以后使用。 KibanaKibana 是一个为 Logstash 和 ElasticSearch 提供的日志分析的 Web 接口。可使用它对日志进行高效的搜索、可视化、分析等各种操作。 搭建方法基于一台主机的搭建，没有使用多台集群，logstah 收集日志后直接写入 elasticseach，可以用 redis 来作为日志队列 jdk 安装jdk 1.8 安装 elasticseach 安装下载地址：https://www.elastic.co/downloads，选择相应的版本 我这里的版本是 elasticsearch-2.4.0 解压目录:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[phachon@localhost elk]$ tar -zxf elasticsearch-2.4.0[phachon@localhost elasticsearch-2.4.0]$# 安装 head 插件[phachon@localhost elasticsearch-2.4.0]$./bin/plugin install mobz/elasticsearch-head[phachon@localhost elasticsearch-2.4.0]$ ls plugins/head编辑 elasticseach 的配置文件[phachon@localhost elasticsearch-2.4.0]$ vim config/elasticseach.yml13 # ---------------------------------- Cluster -----------------------------------14 #15 # Use a descriptive name for your cluster:16 #17 cluster.name: es_cluster #这里是你的el集群的名称18 #19 # ------------------------------------ Node ------------------------------------20 #21 # Use a descriptive name for the node:22 #23 node.name: node0 # elseach 集群中的节点24 #25 # Add custom attributes to the node:26 #27 # node.rack: r128 #29 # ----------------------------------- Paths ------------------------------------30 #31 # Path to directory where to store the data (separate multiple locations by comma):32 #33 path.data: /tmp/elasticseach/data #设置 data 目录34 #35 # Path to log files:36 #37 path.logs: /tmp/elasticseach/logs # 设置 logs 目录#39 # ----------------------------------- Memory -----------------------------------40 #41 # Lock the memory on startup:42 #43 # bootstrap.memory_lock: true44 #45 # Make sure that the `ES_HEAP_SIZE` environment variable is set to about half the memory46 # available on the system and that the owner of the process is allowed to use this limit.47 #48 # Elasticsearch performs poorly when the system is swapping the memory.49 #50 # ---------------------------------- Network -----------------------------------51 #52 # Set the bind address to a specific IP (IPv4 or IPv6):53 #54 # network.host: 192.168.0.155 network.host: 192.168.30.128 # 这里配置本机的 ip 地址,这个是我的虚拟机的 ip 56 #57 # Set a custom port for HTTP:58 #59 http.port: 9200 # 默认的端口 其他配置可先不设置启动 elstaicseach 1[root@localhost elasticsearch-2.4.0]$ ./bin/elasticsearch 注意，这里肯定会报错： 1234567[root@localhost elasticsearch-2.4.0]# ./bin/elasticsearchException in thread &quot;main&quot; java.lang.RuntimeException: don&apos;t run elasticsearch as root.at org.elasticsearch.bootstrap.Bootstrap.initializeNatives(Bootstrap.java:94)at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:160)at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:286)at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)Refer to the log for complete error details. 之前在网上搜的教程这里都没有详细说明，导致花了很长时间卡在这里安装不成功。提示的原因已经说的很清楚了，不能以 root 权限来安装 elasticseach为 elsearch 添加专门的用户组和用户 123[root@localhost elasticsearch-2.4.0]# groupadd elsearch[root@localhost elasticsearch-2.4.0]# adduser -G elsearch elsearch[root@localhost elasticsearch-2.4.0]# passwd elsearch 123456 将 elasticseach 的安装目录设置为 elsearch 用户组和用户所有 1[root@localhost elk]# chown -R elsearch:elsearch elasticsearch-2.4.0/ 别忘了将 /tmp/elasticseach/data 和 /tmp/elasticseach/logs 目录也设置为 elsearch 用户所有,要不然会没有权限读写 1[root@localhost tmp]# chown -R elsearch:elsearch elasticseach/ 好了。终于设置完毕。切换到 elsearch 重新启动 123456789101112131415161718192021[elsearch@localhost elasticsearch-2.4.0]# ./bin/elasticsearch[2016-09-22 01:51:42,102][WARN ][bootstrap] unable to install syscall filter: seccomp unavailable: requires kernel 3.5+ with CONFIG_SECCOMP andCONFIG_SECCOMP_FILTER compiled in[2016-09-22 01:51:42,496][INFO ][node] [node0] version[2.4.0], pid[4205], build[ce9f0c7/2016-08-29T09:14:17Z][2016-09-22 01:51:42,496][INFO ][node] [node0] initializing ...[2016-09-22 01:51:43,266][INFO ][plugins] [node0] modules [reindex, lang-expression, lang-groovy], plugins [head], sites [head][2016-09-22 01:51:43,290][INFO ][env] [node0] using [1] data paths, mounts [[/ (/dev/sda5)]], net usable_space [8.4gb], net total_space [14.6gb], spins?[possibly], types [ext4][2016-09-22 01:51:43,290][INFO ][env] [node0] heap size [998.4mb], compressed ordinary object pointers [unknown][2016-09-22 01:51:43,290][WARN ][env] [node0] max file descriptors [4096] for elasticsearch process likely too low, consider increasing to at least[65536][2016-09-22 01:51:45,697][INFO ][node] [node0] initialized[2016-09-22 01:51:45,697][INFO ][node] [node0] starting ...[2016-09-22 01:51:45,832][INFO ][transport] [node0] publish_address &#123;192.168.30.128:9300&#125;, bound_addresses &#123;192.168.30.128:9300&#125;[2016-09-22 01:51:45,839][INFO ][discovery] [node0] es_cluster/kJMDfFMwQXGrigfknNs-_g[2016-09-22 01:51:49,039][INFO ][cluster.service] [node0] new_master &#123;node0&#125;&#123;kJMDfFMwQXGrigfknNs-_g&#125;&#123;192.168.30.128&#125;&#123;192.168.30.128:9300&#125;, reason:zen-disco-join(elected_as_master, [0] joins received)[2016-09-22 01:51:49,109][INFO ][http] [node0] publish_address &#123;192.168.30.128:9200&#125;, bound_addresses &#123;192.168.30.128:9200&#125;[2016-09-22 01:51:49,109][INFO ][node] [node0] started[2016-09-22 01:51:49,232][INFO ][gateway] [node0] recovered [2] indices into cluster_state 启动成功在本机浏览器访问 http://192.168.30.128:9200 说明搜索引擎 API 返回正常。注意要在服务器将 9200 端口打开，否则访问失败。 打开我们刚刚安装的 head 插件http://192.168.30.128:9200/_plugin/head/ 如果是第一次搭建好，里面是没有数据的，node0 节点也没有集群信息，这里我搭建完成后已经添加了数据。所以显示的有信息 Logstash安装下载地址：https://www.elastic.co/downloads，选择相应的版本 我这里的版本是 logstash-2.4.0.tar.gz解压目录： 12[root@localhost elk]# tar -zxvf logstash-2.4.0[root@localhost elk]# cd logstash-2.4.0 编辑 logstash 配置文件： 12[root@localhost logstash-2.4.0]# mkdir config[root@localhost logstash-2.4.0]# vim config/logstash.conf 这里因为为了简单来显示一下数据，我这里将 apache 的日志作为数据源，也就是 logstash 的 input，直接输出到 elstaticseach 里，即 ouput 1234567891011121314151617181920input &#123; # For detail config for log4j as input, # See: https://www.elastic.co/guide/en/logstash/ file &#123; type =&gt; &quot;apache-log&quot; # log 名 path =&gt; &quot;/etc/httpd/logs/access_log&quot; # log 路径 &#125;&#125;filter &#123; #Only matched data are send to output. 这里主要是用来过滤数据&#125;output &#123; # For detail config for elasticsearch as output, # See: https://www.elastic.co/guide/en/logstash/current elasticsearch &#123; action =&gt; &quot;index&quot; #The operation on ES hosts =&gt; &quot;192.168.30.128:9200&quot; #ElasticSearch host, can be array. # elasticseach 的 host index =&gt; &quot;apachelog&quot; #The index to write data to. &#125;&#125; 使用命令来检测配置文件是否正确 12[root@localhost logstash-2.4.0]# ./bin/logstash -f config/logstash.conf --configtestConfiguration OK 启动 logstash 来收集日志 123[root@localhost logstash-2.4.0]# ./bin/logstash -f config/logstash.confSettings: Default pipeline workers: 4Pipeline main started 好了，logstash 可以开始收集日志了，当日志文件有变化时，会动态的写入到 elastaticseach 中，先让我们来产生一些日志吧。刷新 http://192.168.30.128/ 一直刷新，apache 产生访问日志。ok，打开我们的 elasticseach 的 web 页面 http://192.168.30.128:9200/_plugin/head/ 这里就出现了我们刚刚配置的 apachelog 的日志，点开数据浏览 这里很详细的列出了我们的日志文件，还有字段，左边可进行相应的搜索，右边点击可查看具体的日志信息。至此我们已经能够收集日志，并进行搜索，接下来我们来将搜索数据可视化成图表 Kibana 的安装下载：https://www.elastic.co/downloads 对应自己的版本, 这里我的版本是：kibana-4.6.1-linux-x86 解压目录： 12[root@localhost elk]# tar -zxvf kibana-4.6.1-linux-x86[root@localhost elk]# cd kibana-4.6.1-linux-x86 编辑配置文件： 12345678910111213141516171819202122232425 [root@localhost kibana-4.6.1-linux-x86]# vim config/kibana.yml # Kibana is served by a back end server. This controls which port to use. server.port: 5601 # kibaba 服务 port # The host to bind the server to. server.host: &quot;192.168.30.128&quot; # 你的kibaba 的服务host # If you are running kibana behind a proxy, and want to mount it at a path, # specify that path here. The basePath can&apos;t end in a slash. # server.basePath: &quot;&quot; # The maximum payload size in bytes on incoming server requests. # server.maxPayloadBytes: 1048576 # The Elasticsearch instance to use for all your queries. elasticsearch.url: &quot;http://192.168.30.128:9200&quot; # elastaticseach 的host # preserve_elasticsearch_host true will send the hostname specified in `elasticsearch`. If you set it to false, # then the host you use to connect to *this* Kibana instance will be sent. # elasticsearch.preserveHost: true# Kibana uses an index in Elasticsearch to store saved searches, visualizations# and dashboards. It will create a new index if it doesn&apos;t already exist.kibana.index: &quot;.kibana&quot; # kibana# The default application to load.# kibana.defaultAppId: &quot;discover&quot;# If your Elasticsearch is protected with basic auth, these are the user credentials# used by the Kibana server to perform maintenance on the kibana_index at startup. Your Kibana 配置比较简单配置完成后开始运行 1234567891011[root@localhost kibana-4.6.1-linux-x86]# ./bin/kibanalog [02:48:34.732] [info][status][plugin:kibana@1.0.0] Status changed from uninitialized to green - Readylog [02:48:34.771] [info][status][plugin:elasticsearch@1.0.0] Status changed from uninitialized to yellow - Waiting for Elasticsearchlog [02:48:34.803] [info][status][plugin:kbn_vislib_vis_types@1.0.0] Status changed from uninitialized to green - Readylog [02:48:34.823] [info][status][plugin:markdown_vis@1.0.0] Status changed from uninitialized to green - Readylog [02:48:34.827] [info][status][plugin:metric_vis@1.0.0] Status changed from uninitialized to green - Readylog [02:48:34.835] [info][status][plugin:elasticsearch@1.0.0] Status changed from yellow to green - Kibana index readylog [02:48:34.840] [info][status][plugin:spyModes@1.0.0] Status changed from uninitialized to green - Readylog [02:48:34.847] [info][status][plugin:statusPage@1.0.0] Status changed from uninitialized to green - Readylog [02:48:34.857] [info][status][plugin:table_vis@1.0.0] Status changed from uninitialized to green - Readylog [02:48:34.867] [info][listening] Server running at http://192.168.30.128:5601 在浏览器运行 http://192.168.30.128:5601 这里要先添加 index，在 输入框输入我们刚刚收集的 apachelog 作为 index 名称 点击 create 创建 右上角选择时间来显示我们的数据访问，下面是数据的访问量 中间的搜索框可输入搜索条件搜索，搜索完成后点击右上角的 save seach 保存搜索数据 点击 visualize 可以画出其他的数据分析图，比如饼状图 选择我们刚刚保存的 chrome 的文件来生成饼状图 因为数据没什么变化，所以只能全部是一样的。还是点击右上角的保存按钮，将饼状图保存为 test 添加到 面板中，点击 dashboard点击 + 号添加 选择 test 来显示到面板，效果如下 这样简单的 ELK 系统就搭建起来了，当然，正真的使用环境中，我们会使用集群搭建。利用 redis 来处理日志队列。 marvel 插件Marvel是Elasticsearch的管理和监控工具，在开发环境下免费使用。拥有更好的数据图表界面。 首先在 elastaticsearch 下安装 marvel-agent 插件 12[elsearch@localhost elasticsearch-2.4.0]$ ./bin/plugin install license[elsearch@localhost elasticsearch-2.4.0]$ ./plugin install marvel-agent 这里注意，必须先执行 license 安装，再执行 marvel-agent 安装，安装完成后重启 elastaticseach接下来 kibana 来安装 marvel 插件 12[root@localhost kibana-4.6.1-linux-x86]# cd bin[root@localhost bin]# ./kibana plugin --install elasticsearch/marvel/latest 安装完成后重启 kibana，选择 marvel 插件 是不是感觉有点高大上。。。 好了 ELK 的基本搭建就算是完成了，接下来我们考虑如何集群来使用这个系统。 欢迎指正， Thanks….","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://phachon.github.io/tags/ELK/"},{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://phachon.github.io/tags/ElasticSearch/"},{"name":"LogStash","slug":"LogStash","permalink":"http://phachon.github.io/tags/LogStash/"},{"name":"Kibana","slug":"Kibana","permalink":"http://phachon.github.io/tags/Kibana/"},{"name":"Marvel","slug":"Marvel","permalink":"http://phachon.github.io/tags/Marvel/"},{"name":"Log","slug":"Log","permalink":"http://phachon.github.io/tags/Log/"},{"name":"Linux","slug":"Linux","permalink":"http://phachon.github.io/tags/Linux/"},{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/tags/Redis/"}]},{"title":"点直播流媒体传输协议之 —— HLS（HTTP Live Streaming）","slug":"hls","date":"2016-09-12T16:00:00.000Z","updated":"2018-09-13T13:02:05.662Z","comments":true,"path":"2016/09/13/hls/","link":"","permalink":"http://phachon.github.io/2016/09/13/hls/","excerpt":"简介在最近一年的工作中接触比较多的是视频点播和直播，也了解到了一些点直播的后端技术，这段时间希望将了解到的一些技术总结下来，这篇文章主要介绍流媒体协议 HLS","text":"简介在最近一年的工作中接触比较多的是视频点播和直播，也了解到了一些点直播的后端技术，这段时间希望将了解到的一些技术总结下来，这篇文章主要介绍流媒体协议 HLS 流媒体协议常用的流媒体协议主要有 HTTP 渐进下载和基于 RTSP/RTP 的实时流媒体协议，这两种协议是完全不同的实现方式。主要区别如下： 一种是分段渐近下载，一种是基于实时流来实现播放 协议不同，HTTP 协议的渐近下载意味着你可以在一台普通的 HTTP 的应用服务器上就可以直接提供点播和直播服务 延迟有差异，HTTP 渐近下载的方式的延迟理论上会略高于实时流媒体协议的播放 渐近下载会生成索引文件，所以需要考虑存储，对 I/O 要求较高 HLS简介HLS （HTTP Live Streaming）是苹果公司实现的基于 HTTP 的流媒体协议，可以实现流媒体的点播和直播播放。当然，起初是只支持苹果的设备，目前大多数的移动设备也都实现了该功能。HTML5 直接支持该协议。 实现原理HLS 点播是常见的分段 HTTP 点播，就是将视频流分成不同的片段，客户端不断的去下载该片段，由于片段之间的分段间隔时间非常短，所以看起来是一条完整的播放流，实现的重点是对于媒体文件的分割。同时，HLS 还支持多码率的切换，客户端可以选择从许多不同的备用源中以不同的速率下载同样的资源，允许流媒体会话适应不同的数据速率。多清晰度就是这样实现的。为了播放媒体流，客户端首先需要获得播放列表文件，也就是根据 HLS 生成的片段列表，该列表中包含每个流媒体的文件，客户端以类似轮询的方式不断重复加载播放列表文件并将片段追加实现流媒体的播放。播放列表文件就是通常我们所说的 m3u8 文件，是以后缀 .m3u8 Content-Type是”application/vnd.apple.mpegurl” 的文件。 m3u8 介绍与分析m3u8 文件本质说其实是采用了编码是 UTF-8 的 m3u 文件。它只是一个纯索引文件，一个文件片段的列表，客户单打开它并不是播放它，而是根据它里面的文件片段找到视频文件的网路地址进行播放 这里抓包抓了一个 m3u8 文件打开看一下究竟是什么： 123456#EXTM3U#EXT-X-VIDEO-INF:VIDEO=559ac1317682fa1fcdc67ed2774e4e1a980e0c264cefceb5c.....#EXT-X-STREAM-INF:PROGRAM-ID=1,BANDWIDTH=245760https://*******.com/video/cif/hNAQ0_jbip4j-0o_BhcdqMwyQxwtwbo1k3vVZhtjbcQ.m3u8#EXT-X-STREAM-INF:PROGRAM-ID=1,BANDWIDTH=491520https://******.com/video/sd/hNAQ0_jbip4j-0o_BhcdqMwyQxwtwbo1k3vVZhtjbcQ.m3u8 分析该 m3u8 文件：123456789#EXTM3U：扩展标记 ，意思是我是 m3u 文件#EXT-X-VIDEO-INF:VIDEO ：这个应该是自己定义的一个标签，指名是视频文件，后面可能跟的是视频标题之类的#EXT-X-STREAM-INF指定一个包含多媒体信息的 media URI 作为PlayList，一般做M3U8的嵌套使用，它只对紧跟后面的URI有效，#EXT-X-STREAM-INF:有以下属性：BANDWIDTH：带宽，491520PROGRAM-ID：该值是一个十进制整数，惟一地标识一个在PlayList文件范围内的特定的描述。一个PlayList 文件中可能包含多个有相同ID的此tag。CODECS：不是必须的。RESOLUTION：分辨率。AUDIO：这个值必须和AUDIO类别的“EXT-X-MEDIA”标签中“GROUP-ID”属性值相匹配。 这里 PlayList 的地址我们发现还是个 m3u8 文件 12https://*******.com/video/cif/hNAQ0_jbip4j-0o_BhcdqMwyQxwtwbo1k3vVZhtjbcQ.m3u8https://******.com/video/sd/hNAQ0_jbip4j-0o_BhcdqMwyQxwtwbo1k3vVZhtjbcQ.m3u8 可以观察发现，这其实是 cif 和 sd 两种不同清晰度的 m3u8 文件，客户端根据网络或者选项去选择不同的清晰度的 m3u8 文件。上面的 m3u8 文件为一级 m3u8 文件，这两个 m3u8 就称为二级 m3u8 文件，那么我们就顺着二级 m3u8 文件继续查看，将其中一个下载到本地打开分析： 12345678910111213141516#EXTM3U#EXT-X-VERSION:3#EXT-X-TARGETDURATION:11#EXTINF:12.400,http://*************/**/M00/00/BB/Cn1GQlfWRFaACQaQAAvsEEMIWI42131.ts#EXTINF:10.000,http://*************/**/M00/00/BB/Cn1GQlfWRFaAJO1mAAaTMDz8P4E9292.ts#EXTINF:10.000,http://*************/**/M00/00/BB/Cn1GQlfWRFaAZ2fyAAVQEM22iWA2544.ts#EXTINF:11.120,http://*************/**/M00/00/BB/Cn1GQlfWRFaAIfwHAAirSMgfpx03176.ts#EXTINF:17.240,http://*************/**/M00/00/BB/Cn1GQlfWRFaAaiz6AAn0SHY1csA7539.ts#EXTINF:3.720,http://*************/**/M00/00/BB/Cn1GQlfWRFaARLJ2AAGYUIIpGKA7707.ts#EXT-X-ENDLIST 12345#EXT-X-VERSION:3 : 版本#EXT-X-TARGETDURATION: 11指定最大的媒体段时间长（秒）。所以#EXTINF中指定的时间长度必须小于或是等于这个最大值。这个tag在整个PlayList文件中只能出现一 次（在嵌套的情况下，一般有真正ts url 的m3u8才会出现该tag）#EXTINF: duration 指定每个媒体段(ts)的持续时间（秒），仅对其后面的URI有效，title是下载资源的url#EXT-X-ENDLIST 结束列表 这里我们看到了真正播放的流片段，ts 片，客户端拿到的就是这个 ts 片，然后不断下载请求到该片段并连续播放。 有些人可能要问了，那 ts 文件又到底是个什么东西呢，那就下载来看看，拿着其中的一个 ts 文件浏览器打开保存到本地： 发现保存到本地的文件就可以直接打开，其实就是真正的流媒体文件，但是这个文件只是片段，大概只有 10s 的时间。 HLS播放实现时序图123456title:流媒体播放实现时序图客户端-&gt;服务端play接口:请求服务端play接口-&gt;客户端:返回一级 m3u8地址客户端-&gt;m3u8文件服务器:获取一级m3u8文件客户端-&gt;m3u8文件服务器:获取二级m3u8文件客户端-&gt;ts文件服务器:不断获取 ts 流媒体文件 HLS 直播HLS 直播原理上还是按点播的方式实现的，通过 http 协议传输，生成 ts 索引文件以及 m3u8 索引文件。直播的复杂在于先要采集视频源和音频源的数据，然后再进行 H264 编码和音频 ACC 编码，并封装成 ts 包，其中还要考虑 ts 的分段生成策略。 下一篇我会介绍一篇关于 rtmp 协议的文章。 欢迎指正，Thanks…","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"HLS","slug":"HLS","permalink":"http://phachon.github.io/tags/HLS/"},{"name":"TS","slug":"TS","permalink":"http://phachon.github.io/tags/TS/"},{"name":"M3U8","slug":"M3U8","permalink":"http://phachon.github.io/tags/M3U8/"}]},{"title":"You-get 的安装与使用","slug":"you-get-install","date":"2016-09-11T16:00:00.000Z","updated":"2018-09-13T13:02:05.666Z","comments":true,"path":"2016/09/12/you-get-install/","link":"","permalink":"http://phachon.github.io/2016/09/12/you-get-install/","excerpt":"You-get 介绍You-Get 是一款命令行工具，用来下载网页中的视频、音频、图片，支持众多网站，包含 41 家国内主流视频、音乐网站，如 网易云音乐、AB 站、百度贴吧、斗鱼、熊猫、爱奇艺、凤凰视频、酷狗音乐、乐视、荔枝FM、秒拍、腾讯视频、优酷土豆、央视网、芒果TV 等等，只需一个命令就能直接下载视频、音频以及图片回来，并且可以自动合并视频。而对于有弹幕的网站，比如 B 站，还可以将弹幕下载回来。本篇文章介绍 you-get 的安装","text":"You-get 介绍You-Get 是一款命令行工具，用来下载网页中的视频、音频、图片，支持众多网站，包含 41 家国内主流视频、音乐网站，如 网易云音乐、AB 站、百度贴吧、斗鱼、熊猫、爱奇艺、凤凰视频、酷狗音乐、乐视、荔枝FM、秒拍、腾讯视频、优酷土豆、央视网、芒果TV 等等，只需一个命令就能直接下载视频、音频以及图片回来，并且可以自动合并视频。而对于有弹幕的网站，比如 B 站，还可以将弹幕下载回来。本篇文章介绍 you-get 的安装 Ubuntu安装官网地址：https://you-get.org/github地址：https://github.com/soimort/you-get/中文说明：https://github.com/soimort/you-get/wiki/%E4%B8%AD%E6%96%87%E8%AF%B4%E6%98%8E安装准备： python3安装方法： 安装 pip3 12sudo apt-get install python3-pip #安装 you-getsudo pip3 install you-get 下载安装 1234sudo wget https://github.com/soimort/you-get/releases/download/v0.4.523/you-get-0.4.523.tar.gzsudo tar -zxvf you-get-0.4.523.tar.gzcd you-getmake install 更新方法: pip3 1pip3 install --upgrade you-get 普通更新 1you-get https://github.com/soimort/you-get/archive/master.zip Windows 安装 安装 Python3 安装比较简单，这里不再说明 安装 pip 下载地址:https://pypi.python.org/pypi/pip#downloads选择 pip-8.1.2.tar.gz (md5, pgp) 下载解压到一个目录下，打开 CMD 命令行，进入该目录执行: python3 setup.py install自动安装 安装完成后，注意一下 pip 安装的路径 我这里的路径是 D:\\Program Files(86)\\python3\\Scripts将pip 的安装路径添加到环境变量中 path 安装 you-get 1pip3 install you-get OK ,Windows 下的 you-get 安装成功.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"http://phachon.github.io/tags/Windows/"},{"name":"You-get","slug":"You-get","permalink":"http://phachon.github.io/tags/You-get/"},{"name":"Python3","slug":"Python3","permalink":"http://phachon.github.io/tags/Python3/"}]},{"title":"Sphinx 在网站应用中的服务架构设计","slug":"sphinx-web","date":"2016-09-05T16:00:00.000Z","updated":"2018-09-13T13:02:05.666Z","comments":true,"path":"2016/09/06/sphinx-web/","link":"","permalink":"http://phachon.github.io/2016/09/06/sphinx-web/","excerpt":"Sphinx 简单介绍 介绍Sphinx 是一个基于 SQL 的全文检索引擎，可以给 Mysql、PostgreSQL 做检索，提供比数据库更加专业的搜索功能。Sphinx 的搜索API接口支持 PHP,Python,Ruby,等。Sphinx 单一索引最大可包含1亿条记录，在1千万条记录情况下的查询速度为0.x秒（毫秒级）。Sphinx创建索引的速度为：创建100万条记录的索引只需 3～4分钟，创建1000万条记录的索引可以在50分钟内完成，而只包含最新10万条记录的增量索引，重建一次只需几十秒 主要特性 高速索引 高速搜索 支持分布式搜索 提供从Mysql 内部的插件式存储引擎上搜索 采用 UTF-8 字符集 支持 Windows/Linux/MacOX 使用场景如果数据库的数据量不是很多，百万级的数据，可以采用数据库索引来进行检索，但是对于上千万的数据量的话就用数据库直接检索的效率就会有所下降，特别对于采用分库分表的数据库设计，如果要检索非主键的字段的话，将会非常麻烦。比如用户表 user，用户量大的时候，我们一般会采用分表的方式来提高应用的访问性能。user_0 ~ user_63 ,总共 64 张表,user_id 作为 主键表结构如下。user_id name password ageint char(100) char(32) int如果知道 user_id = 65，那我们很容易找到用户的信息, 65 % 64 = 1，那就在 user_1 表中，采用 select from user_1 ….但是如果我想检索名字叫 “phachon” 的用户，这个就比较麻烦了，最笨的办法就是每一张表都去查找 select from user_* where name LIKE %phchon% ,这样要循环 64 次，再将数据合并起来，这样显然是不可行的，数据库的开销太大，造成应用程序的性能下降。 Sphinx 就可以帮我们解决上面所说的问题。当然，Sphinx 可以应用的场景很多，上面只是其中的一种。","text":"Sphinx 简单介绍 介绍Sphinx 是一个基于 SQL 的全文检索引擎，可以给 Mysql、PostgreSQL 做检索，提供比数据库更加专业的搜索功能。Sphinx 的搜索API接口支持 PHP,Python,Ruby,等。Sphinx 单一索引最大可包含1亿条记录，在1千万条记录情况下的查询速度为0.x秒（毫秒级）。Sphinx创建索引的速度为：创建100万条记录的索引只需 3～4分钟，创建1000万条记录的索引可以在50分钟内完成，而只包含最新10万条记录的增量索引，重建一次只需几十秒 主要特性 高速索引 高速搜索 支持分布式搜索 提供从Mysql 内部的插件式存储引擎上搜索 采用 UTF-8 字符集 支持 Windows/Linux/MacOX 使用场景如果数据库的数据量不是很多，百万级的数据，可以采用数据库索引来进行检索，但是对于上千万的数据量的话就用数据库直接检索的效率就会有所下降，特别对于采用分库分表的数据库设计，如果要检索非主键的字段的话，将会非常麻烦。比如用户表 user，用户量大的时候，我们一般会采用分表的方式来提高应用的访问性能。user_0 ~ user_63 ,总共 64 张表,user_id 作为 主键表结构如下。user_id name password ageint char(100) char(32) int如果知道 user_id = 65，那我们很容易找到用户的信息, 65 % 64 = 1，那就在 user_1 表中，采用 select from user_1 ….但是如果我想检索名字叫 “phachon” 的用户，这个就比较麻烦了，最笨的办法就是每一张表都去查找 select from user_* where name LIKE %phchon% ,这样要循环 64 次，再将数据合并起来，这样显然是不可行的，数据库的开销太大，造成应用程序的性能下降。 Sphinx 就可以帮我们解决上面所说的问题。当然，Sphinx 可以应用的场景很多，上面只是其中的一种。 Sphinx 在网站应用程序中的应用架构设计以下是最近在工作中使用 Sphinx 来进行后台数据检索的应用架构设计 web application 应用程序层 select 操作只用请求 Server Api 层的 select 接口；update/insert/delete 操作先操作数据库再请求 Server Api 的 update 更新接口。Server Api 层通过 Nginx + php 连接 Sphinx 客户端，主要提供了两个接口 select 查询接口和 update 更新接口。select 接口需要查询全量（main）索引和增量（delta）做索引的数据，取其数据的交集才是真正需要的数据。Sphinx 客户端建了两个索引，全量索引（main）和增量索引（delta），每天凌晨 1 点通过脚本进行定时任务重建索引，如果插入或者修改量很低的话，重建索引的频率可适当调整。应用层更新操作可通过消息队列来异步实现。DB 数据库层读库和写库及时同步保证数据的一致性。 Server Api 层连接 Sphinx 客户端的可使用 SphinxClinet 类或者 foolz/sphinxql-query-builder 类来实现。 Sphinx 配置Sphinx 在 Linux 下的安装可参考之前写的一篇文章《Sphinx 在Linux下的安装与基本配置》","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://phachon.github.io/tags/Linux/"},{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/tags/Mysql/"},{"name":"Sphinx","slug":"Sphinx","permalink":"http://phachon.github.io/tags/Sphinx/"}]},{"title":"Sphinx 在 Linux 下的安装与基本配置","slug":"sphinx-install","date":"2016-09-05T16:00:00.000Z","updated":"2018-09-13T13:02:05.665Z","comments":true,"path":"2016/09/06/sphinx-install/","link":"","permalink":"http://phachon.github.io/2016/09/06/sphinx-install/","excerpt":"下载Sphinx 官网：http://sphinxsearch.com/wget http://sphinxsearch.com/files/sphinx-2.2.10-release.tar.gz 安装解压压缩包12tar zxvf sphinx-2.2.10-release.tar.gzcd sphinx-2.2.10-release 找到 mysql 的安装目录，我的是在 /usr/bin/mysql 执行 /usr/lcoal/sphinx 为 sphinx 的安装目录。 123sudo ./configure --prefix=/usr/local/sphinx --with-mysql=/usr/local/mysqlmake make install 不出问题的话应该已经安装成功了","text":"下载Sphinx 官网：http://sphinxsearch.com/wget http://sphinxsearch.com/files/sphinx-2.2.10-release.tar.gz 安装解压压缩包12tar zxvf sphinx-2.2.10-release.tar.gzcd sphinx-2.2.10-release 找到 mysql 的安装目录，我的是在 /usr/bin/mysql 执行 /usr/lcoal/sphinx 为 sphinx 的安装目录。 123sudo ./configure --prefix=/usr/local/sphinx --with-mysql=/usr/local/mysqlmake make install 不出问题的话应该已经安装成功了 其他参数的配置 12345--with-mysql-includes=/usr/local/mysql/include/mysql/--with-mysql-libs=/usr/local/mysql/lib/mysql/--with-mmseg=/usr/local/mmseg/--with-mmseg-includes=/usr/local/mmseg/include/mmseg/--with-mmseg-libs=/usr/local/mmseg/lib/ 配置找到 sphinx 的安装目录 /usr/local/sphinx/etc .复制一份 sphinx.conf.dist 为 test.conf打开文件对照注释编写配置文件。由于都是英文，这里将经常用到的一些配置做解释如下： 数据源配置解析： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273source &#123; # 数据源类型 mysql，pgsql，mssql，xmlpipe，xmlpipe2，odbc type = mysql # -------------------------连接sql数据源的一些配置--------------------------- sql_host = localhost sql_user = root sql_pass = 123456 sql_db = test sql_port = 3306 # 使用 unix sock连接可以使用这个 #sql_sock = /tmp/mysql.sock # --------------------------mysql 相关配置---------------------------------------- # mysql 与 sphinx 之间的交互，0/32/2048/32768 无/使用压缩协议/握手后切换到ssl/Mysql 4.1版本身份认证。 mysql_connect_flags = 32 ## 当mysql_connect_flags设置为2048（ssl）的时候，下面几个就代表ssl连接所需要使用的几个参数。 # mysql_ssl_cert = /etc/ssl/client-cert.pem # mysql_ssl_key = /etc/ssl/client-key.pem # mysql_ssl_ca = /etc/ssl/cacert.pem #---------------------------mssql 相关配置---------------------------------------- # 是否使用 windows 登陆 # mssql_winauth = 1 # 使用unicode还是单字节数据 # mssql_unicode = 1 #----------------------------odbc 相关配置------------------------------------------- odbc_dsn = DBQ=C:\\data;DefaultDir=C:\\data;Driver=&#123;Microsoft Text Driver (*.txt; *.csv)&#125;; #-----------------------------sql 相关配置-------------------------------------------- # sql某一列的缓冲大小，一般是针对字符串来说的 # sql_column_buffers = content=12M, comments=1M # 索引的 sql 执行前需要执行的操作，比如设置字符串为 utf8 sql_query_pre = SET NAMES utf8 # 索引的 sql 执行语句 sql_query = SELECT id, name, age FROM test # 联合查询 # sql_joined_field是增加一个字段，这个字段是从其他表查询中查询出来的。 # 如果是query，则返回id和查询字段，如果是payload-query，则返回id，查询字段和权重 # 查询需要按照id进行升序排列 # sql_joined_field = tags from query; SELECT docid, CONCAT(&apos;tag&apos;,tagid) FROM tags ORDER BY docid ASC # sql_joined_field = wtags from payload-query; SELECT docid, tag, tagweight FROM tags ORDER BY docid ASC #----------------------------字段属性的配置（用于过滤和排序）---------------------------------------- # uint无符号整型属性 sql_attr_uint = id # 布尔值属性 # sql_attr_bool = is_deleted # 长整型属性(有负数用 bigint) # sql_attr_bigint = my_bigint_id # 时间戳属性，经常被用于做排序 sql_attr_timestamp = date_added # 字符串排序属性。一般我们按照字符串排序的话，我们会将这个字符串存下来进入到索引中，然后在查询的时候比较索引中得字符大小进行排序。 # 但是这个时候索引就会很大，于是我们就想到了一个方法，我们在建立索引的时候，先将字符串值从数据库中取出，暂存，排序。 # 然后给排序后的数组分配一个序号，然后在建立索引的时候，就将这个序号存入到索引中去。这样在查询的时候也就能完成字符串排序的操作。 # 这，就是这个字段的意义。 # sql_attr_str2ordinal = author_name # 浮点数属性 # sql_attr_float = lat_radians # sql_attr_float = long_radians # 字符串属性 # sql_attr_string = stitle # 文档词汇数记录属性。比如下面就是在索引建立的时候增加一个词汇数的字段 # sql_attr_str2wordcount = stitle&#125; # sphinx 的 source 有继承属性，也就是说共有的部分可以写在父级数据源中，比如数据库连接配置信息 source main_0: main&#123; sql_ranged_throttle = 100&#125; 索引配置解析： 12345678910111213141516index test1&#123; # 索引类型，包括有plain，distributed和rt。分别是普通索引/分布式索引/增量索引。默认是plain。 # type = plain # 索引数据源 source = src1 # 索引文件存放路径 path =/usr/local/sphinx/var/data/src1 # 字符集编码类型，可以为sbcs,utf-8 charset_type = utf-8 # 字符表和大小写转换规则 # &apos;sbcs&apos; default value is # charset_table = 0..9, A..Z-&gt;a..z, _, a..z, U+A8-&gt;U+B8, U+B8, U+C0..U+DF-&gt;U+E0..U+FF, U+E0..U+FF # &apos;utf-8&apos; default value is # charset_table = 0..9, A..Z-&gt;a..z, _, a..z, U+410..U+42F-&gt;U+430..U+44F, U+430..U+44F&#125; 搜索服务searchd 配置 12345678910111213141516171819202122232425262728293031323334353637searchd&#123; # 监听端口 listen = 9312 listen = 9307:mysql4 # 监听日志路径 log = /usr/local/sphinx/var/log/searchd.log # 查询日志路径 query_log = /usr/local/sphinx/var/log/query.log # 客户端读超时时间 read_timeout = 5 # 客户端持久时间 client_timeout = 300 #并行执行搜索数量 max_children = 0 #进程 pid 文件 pid_file = /usr/local/sphinx/var/log/searchd.pid #当进行索引轮换的时候，可能需要消耗大量的时间在轮换索引上。 # 启动了无缝轮转，就以消耗内存为代价减少轮转的时间 seamless_rotate = 1 # 索引预开启，强制重新打开所有索引文件 preopen_indexes = 1 # 索引轮换成功之后，是否删除以.old为扩展名的索引拷贝 unlink_old = 1 # 多值属性MVA更新的存储空间的内存共享池大小 mva_updates_pool = 1M #网络通讯时允许的最大的包的大小 max_packet_size = 8M # 每次查询允许设置的过滤器的最大个数 max_filters = 256 # 单个过滤器允许的值的最大个数 max_filter_values = 4096 # 每次批量查询的查询数限制 max_batch_queries = 32 # 多处理模式（MPM）。 可选项；可用值为none、fork、prefork，以及threads。 默认在Unix类系统为form，Windows系统为threads。 workers = form&#125; 开启sphinx生成索引1/usr/local/sphinx/bin/indexer --config /usr/local/sphinx/etc/test.conf --all 打开 sphinx 进程1/usr/local/sphinx/bin/searchd --config /usr/local/sphinx/etc/sphinx.conf 参考 http://www.cnblogs.com/yjf512/p/3598332.html","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://phachon.github.io/tags/Linux/"},{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/tags/Mysql/"},{"name":"Sphinx","slug":"Sphinx","permalink":"http://phachon.github.io/tags/Sphinx/"}]},{"title":"IO 模型简介","slug":"io","date":"2016-09-04T16:00:00.000Z","updated":"2018-09-13T13:02:05.662Z","comments":true,"path":"2016/09/05/io/","link":"","permalink":"http://phachon.github.io/2016/09/05/io/","excerpt":"最近工作中接触到关于网络编程的一些东西，发现对于网络、IO编程、socket、进程、线程、协程、TCP/IP等基本知识理解不够深入。所以需要从头到尾总结一下。","text":"最近工作中接触到关于网络编程的一些东西，发现对于网络、IO编程、socket、进程、线程、协程、TCP/IP等基本知识理解不够深入。所以需要从头到尾总结一下。 什么是 IOIO 的英文来源是 Input/Output，即输入/输出，我们的程序和数据在运行过程中会在内存中驻留，由 CPU 来计算，涉及到数据交换的地方，就需要IO接口，IO 包括网络 IO, 内存 IO,磁盘IO等。 IO编程中，Stream（流）是一个很重要的概念，可以把流想象成一个水管，数据就是水管里的水，但是只能单向流动。Input Stream就是数据从外面（磁盘、网络）流进内存，Output Stream就是数据从内存流到外面去。对于浏览网页来说，浏览器和服务器之间至少需要建立两根水管，才可以既能发数据，又能收数据。（摘自http://www.liaoxuefeng.com/） IO 模型大概分为 阻塞 IO（blocking IO） 非阻塞 IO（non-blocking IO） IO 复用（IO multiplexing） 异步 IO（asynchronous IO） 同步 IO（synchronous IO） 但是这几种 IO 模型到底是什么，又分别有什么区别。这里我搜索了一些资料并融入自己的理解详细解释一下。 阻塞 IO（blocking IO）这里先从阻塞 IO 说起，因为 Linux 中默认的网路模型基本都是阻塞 IO。根据调用关系粗略画的时序图如下： 当用户进程调用 recvform 这个系统调用，linux 内核 kernel 开始工作：准备接受数据， 数据一开始往往还没有到达，（例如，网络IO还没有接受到一个完整的 UDP包），这个时候 kernel 需要等待一段时间来接受完数据。在这个过程中，用户进程就会什么也做不了，只能等 kernel 接受完数据并拷贝数据到用户内存中，然后返回消息给用户进程，进程才能继续操作。对于用户进程来说，等待 kernel 返回数据的过程就叫阻塞（block）。等数据返回才能解除阻塞。所以，阻塞 IO 模型的特点就是在 IO 执行的输入和输出，都被阻塞掉了。 打个比喻：去餐厅吃饭，点餐完，你在柜台一直等饭，柜台接受到你的订单开始准备做饭，这时候你只能一直等哪里也不能去，就像是被阻塞，等饭出来了，你拿着饭才走。解除阻塞。 非阻塞 IO non-blocking IO了解了阻塞 IO，我们来看看非阻塞IO模型的具体流程。还是以用户进程的一次调用为例，调用时序图大致如下： 当用户进程调用系统调用，kernel 内核开始准备接受数据，如果一开始没有接受到数据，会立刻返回 error 给用户进程，用户进程就知道数据还没有准备好，就会再次发送调用，直到数据准备好，然后立刻会将数据拷贝到内存中，并返回信息给用户进程，在这个过程中用户进程并不需要等待，每次调用开始到结束的过程，如果出错，kernel 都会立刻返回 error 消息给它。这种模型被称为非阻塞 IO 模型。非阻塞IO 模型的特点是不需要等待，但是需要用户进程不断的去调用。 需要注意的是， 在我的理解下，在系统调用时，如果没有准备好数据就立刻返回给进程 error 信息，这个过程确实是非阻塞的，但是，当数据准备好之后，kernel 开始将数据拷贝到内存中的这段时间内，用户进程其实还是阻塞的。 又打个比喻：还是上面说的去餐馆吃饭，当在柜台点完餐，这个时候服务员说现在做饭需要的食材还没有准备好，你知道了这个信息后，隔一会就去重新点一次餐，最终服务员说食材准备好了，并做好了饭给你。在做饭的过程中可能会不断遇到各种问题不能下单，你只能去不断的重新点餐。 IO 复用非阻塞模型中存在的问题是用户进程需要不断去调用内核，IO 复用模型的出现就是来解决这个问题的，IO 复用模型是建立在内核提供的多路分离函数 select 函数之上的，一个 select 中可以同时处理多个 socket 请求。所以用户一次调用可以注册多个 socket 请求。时序图大致如下： 用户进程使用select 函数注册多个 socket 请求，这时候整个进程就会被阻塞，kernel会“监视”所有select负责的socket，只要其中的一个 socket 请求的数据准备成功，select 就会返回给用户进程可读的消息，这个时候用户进程再调用 read 操作去讲数据拷贝到 内存中。在这个模型中，我们一般设置 select 中的每个 socket 为非阻塞的，但是其实整个进程是被 select 阻塞的。IO 复用的特点是需要两次系统调用（system），并且需要调用 select ，可以同时处理多个 socket 连接。如果处理的连接数不是很高的话，使用select/epoll的 web server 不一定比使用 multi-threading + blocking IO 的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。 异步IO（asynchronous IO）异步IO模型中，当用户发起请求之后，就会立刻得到返回，并去做其他事情去了，从 kernel 角度来讲，他在接受到请求会立刻返回给用户进程消息，不会对其造成任何的阻塞，然后 kernel 会自己等待数据接受完毕并将数据拷贝到内存中，当这一切都完成后 kernel 会发送一个消息给用户进程，告诉它已经操作完成。时序图如下: 相比于IO多路复用模型，异步IO并不十分常用，不少高性能并发服务程序使用IO多路复用模型+多线程任务处理的架构基本可以满足需求。况且目前操作系统对异步IO的支持并非特别完善，更多的是采用IO多路复用模型模拟异步IO的方式（IO事件触发时不直接通知用户线程，而是将数据读写完毕后放到用户指定的缓冲区中）。 同步IO同步IO 的概念是：一个同步 IO 的操作会导致请求的进程被阻塞，直到整个进程完成。有的人可能要说了，阻塞IO 和 IO 多路复用是同步 IO, 非阻塞IO 就是同步 IO。我的理解不是这样的，阻塞IO 和多路复用 IO 肯定是同步 IO，但非阻塞IO 其实本质上也是同步 IO。在非阻塞IO 那里，最后写了需要注意的一个问题，就是当数据准备好之后，kernel 拷贝数据到内存的过程中对于进程来说其实还是阻塞的。并不完全是非阻塞的。 所以，阻塞 IO、非阻塞 IO、IO 多路复用都是同步 IO 区别阻塞 IO 和非阻塞 IO 的区别：请求发起调用 IO 会一直被 block，直到操作完成。而 non-blocking IO在kernel还准备数据的情况下会立刻返回。同步 IO 和异步 IO 的区别：一个IO操作有没有对进程造成阻塞。 参考 https://segmentfault.com/a/1190000003063859#articleHeader11 http://blog.csdn.net/historyasamirror/article/details/5778378","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://phachon.github.io/tags/Linux/"},{"name":"IO","slug":"IO","permalink":"http://phachon.github.io/tags/IO/"}]},{"title":"CronTab 解决周期内未执行完重复执行","slug":"crontab","date":"2016-08-22T16:00:00.000Z","updated":"2018-09-13T13:02:05.660Z","comments":true,"path":"2016/08/23/crontab/","link":"","permalink":"http://phachon.github.io/2016/08/23/crontab/","excerpt":"crontab 执行 php 脚本linux 下的 crontab 定时任务服务，可以用来定时运行脚本。工作中经常会用到这样的服务，使用起来比较简单。 12345678/sbin/service crond start # 开启服务/sbin/service crond stop # 停止服务/sbin/service crond restart #重启服务/sbin/service crond reload #重新加载服务sudo crontab -e #插入一条定时任务sudo crontab -l #查看所有的 root 用户下的定时任务列表tail -f /var/log/cron # 实时查看定时任务日志","text":"crontab 执行 php 脚本linux 下的 crontab 定时任务服务，可以用来定时运行脚本。工作中经常会用到这样的服务，使用起来比较简单。 12345678/sbin/service crond start # 开启服务/sbin/service crond stop # 停止服务/sbin/service crond restart #重启服务/sbin/service crond reload #重新加载服务sudo crontab -e #插入一条定时任务sudo crontab -l #查看所有的 root 用户下的定时任务列表tail -f /var/log/cron # 实时查看定时任务日志 123# 例如，添加如下一条定时任务# 分 时 日 月 周* * * * * php test.php 重复执行问题最近在工作中经常会用到定时任务，发现当我们的脚步的执行时间（假设：130s）大于定时任务的设定时间（假设：1分钟）时，定时任务会重复开始执行，即上次的任务还没有执行完，下次的任务的又开始执行。往往执行的脚本里的资源是不允许同时两个脚本同时共享资源，即保证操作的原子性。这样会造成执行出错，下面我们来验证一下。 以下是一个测试的 php 脚本，该脚本执行一次需要 130s 123456789&lt;?php$time = time();$id = uniqid(); //一次执行的唯一标示file_put_contents(&apos;/home/phachon/cron/test.log&apos;, &quot;id: &quot;.$id.&quot; 时间：&quot;.date(&apos;Y-m-d H:i:s&apos;, $time).&quot;-开始\\n&quot;, FILE_APPEND);while(time() - $time &lt; 130) &#123; &#125;file_put_contents(&apos;/home/phachon/cron/test.log&apos;, &quot;id: &quot;.$id.&quot; 时间：&quot;.date(&apos;Y-m-d H:i:s&apos;, time()).&quot;-结束\\n&quot;, FILE_APPEND); 然后添加定时任务，每分钟（60s）执行一次 1*/1 * * * * php /home/phachon/cron/test.php 过一段时间后，查看日志： 1234567891011121314id: 57bbcd4d10262 时间：2016-08-23 12:13:01-开始id: 57bbcd890e7f7 时间：2016-08-23 12:14:01-开始id: 57bbcdc510685 时间：2016-08-23 12:15:01-开始id: 57bbcd4d10262 时间：2016-08-23 12:15:11-结束id: 57bbce010a78d 时间：2016-08-23 12:16:01-开始id: 57bbcd890e7f7 时间：2016-08-23 12:16:11-结束id: 57bbce3d0f68e 时间：2016-08-23 12:17:01-开始id: 57bbcdc510685 时间：2016-08-23 12:17:11-结束id: 57bbce790d90f 时间：2016-08-23 12:18:01-开始id: 57bbce010a78d 时间：2016-08-23 12:18:11-结束id: 57bbceb50eef8 时间：2016-08-23 12:19:01-开始id: 57bbce3d0f68e 时间：2016-08-23 12:19:11-结束id: 57bbce790d90f 时间：2016-08-23 12:20:11-结束id: 57bbceb50eef8 时间：2016-08-23 12:21:11-结束 分析日志我们会发现 id = 57bbcd4d10262 的任务在 12:13:01 开始，但是还没有结束的时候，id=57bbcd890e7f7 和 id=57bbcdc510685 的任务就已经开始了，这样明显存在问题。我们想要的是每次单独执行完后，下一个执行开始: 1234id: 57bbcd4d10262 时间：2016-08-23 12:13:01-开始id: 57bbcd4d10262 时间：2016-08-23 12:15:11-结束id: 57bbcd890e7f7 时间：2016-08-23 12:14:01-开始id: 57bbcd890e7f7 时间：2016-08-23 12:16:11-结束 解决办法 利用临时文件 思路很简单，在执行文件的开头先判断是否有一个 test.lock 的文件，如果有 test.lock 文件，则 exit()，如果没有的话，创建 test.lock 文件，然后执行脚本文件，执行完毕删除 test.lock;实现后代码： 12345678910111213141516&lt;?php $time = time(); $id = uniqid(); $lock = '/home/phachon/cron/lock/test.lock'; if(file_exists($lock)) &#123; exit('no'); &#125; touch($lock); file_put_contents('/home/phachon/cron/test2.log', \"id: \".$id.\" 时间：\".date('Y-m-d H:i:s', $time).\"-开始\\n\", FILE_APPEND); while(time() - $time &lt; 130) &#123; &#125; file_put_contents('/home/phachon/cron/test2.log', \"id: \".$id.\" 时间：\".date('Y-m-d H:i:s', time()).\"-结束\\n\", FILE_APPEND); unlink($lock); 查看日志如下： 1234id: 57bbdd3d6b5e8 时间：2016-08-23 13:21:01-开始id: 57bbdd3d6b5e8 时间：2016-08-23 13:23:11-结束id: 57bbddf10ecb9 时间：2016-08-23 13:24:01-开始id: 57bbddf10ecb9 时间：2016-08-23 13:26:11-结束 利用脚本加锁 思路和第一种方式类似，只是不是用文件判断的方式，而是给文件加锁的方式 实现代码： 12345678910111213&lt;?php$fp = fopen(\"/tmp/lock.txt\", \"w+\");// 进行排它型锁定if (flock($fp, LOCK_EX | LOCK_NB)) &#123; //执行任务 run(); // 释放锁定 flock($fp, LOCK_UN); &#125; else &#123; echo \"文件被锁定\";&#125;fclose($fp);?&gt; 第一种和第二种方法本质思路一样，确实也解决了问题，但是这样需要加代码在我们的脚本里，而且，这样其实 crontab 服务还是多了很多不必要的执行，浪费资源。我们需要找到更加好的方法，在执行代码前就已经判断是否可以执行脚本。 利用 linux flock 锁机制 利用 flock（FreeBSD lockf，CentOS下为 flock），在脚本执行前先检测能否获取某个文件锁，以防止脚本运行冲突。 格式： 12flock [-sxun][-w #] fd#flock [-sxon][-w #] file [-c] command 选项： 123456789-s, --shared: 获得一个共享锁 -x, --exclusive: 获得一个独占锁 -u, --unlock: 移除一个锁，脚本执行完会自动丢弃锁 -n, --nonblock: 如果没有立即获得锁，直接失败而不是等待 -w, --timeout: 如果没有立即获得锁，等待指定时间 -o, --close: 在运行命令前关闭文件的描述符号。用于如果命令产生子进程时会不受锁的管控 -c, --command: 在shell中运行一个单独的命令 -h, --help 显示帮助 -V, --version: 显示版本 锁类型： 共享锁：多个进程可以使用同一把锁，常被用作读共享锁 独占锁：同时只允许一个进程使用，又称排他锁，写锁。 这里我们需要同时只允许一个进程使用，所以使用独占锁。 修改后的定时任务如下： 1*/1 * * * * flock -xn /tmp/test.lock -c &apos;php /home/phachon/cron/test.php&apos; &gt;&gt; /home/phachon/cron/cron.log&apos; 日志如下： 1234id: 57bbf255e4b2b 时间：2016-08-23 14:51:01-开始id: 57bbf255e4b2b 时间：2016-08-23 14:53:11-结束id: 57bbf3090eca0 时间：2016-08-23 14:54:01-开始id: 57bbf3090eca0 时间：2016-08-23 14:56:11-结束 完美的解决了我们的问题 总体看来，还是用第三种方法比较好，而且也方便.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"},{"name":"CronTab","slug":"CronTab","permalink":"http://phachon.github.io/tags/CronTab/"}]},{"title":"CentOS6.3+Apache2.2+php5.3.8+Mysql5.5.4源码搭建Lump环境","slug":"lump-install","date":"2016-07-28T16:00:00.000Z","updated":"2018-09-13T13:02:05.664Z","comments":true,"path":"2016/07/29/lump-install/","link":"","permalink":"http://phachon.github.io/2016/07/29/lump-install/","excerpt":"系统环境 虚拟机VMware 下CentOS 6.3最小化安装。 PHP版本：php-5.3.8.tar.gz Apache版本：httpd-2.2.31.tar.gz MySql版本：MySql-5.5.45.tar.gz","text":"系统环境 虚拟机VMware 下CentOS 6.3最小化安装。 PHP版本：php-5.3.8.tar.gz Apache版本：httpd-2.2.31.tar.gz MySql版本：MySql-5.5.45.tar.gz 安装前准备安装所需要的库文件在安装PHP之前，应先安装PHP5需要的最新版本库文件，例如libxml2、libmcrypt以及GD2库等文件。安装GD2库是为了让PHP5支 持GIF、PNG和JPEG图片格式，所以在安装GD2库之前还要先安装最新的zlib、libpng、freetype和jpegsrc等库文件。 autoconf-2.61.tar.gz freetype-2.3.5.tar.gz gd-2.0.35.tar.gz jpegsrc.v6b.tar.gz libmcrypt-2.5.8.tar.gz libpng-1.2.31.tar.gz libxml2-2.6.30.tar.gz zlib-1.2.3.tar.gz 下载安装包有两种方式： (1).利用wget 工具 先 yum install –y wget 安装wget .然后用 wgethttp://www.......com./ksk 下载 (2).利用 rz sz 命令将windows 下载好的包上传到 linux下 12yum install –y lrzsz 输入rz 弹出windows框选好安装包上传。cd /usr/local/src 进入到src目录下，将所有的安装包都放在这个目录下（方便管理）。 必须先安装gcc、gc-c++用来编译 这里采用yum安装即可。12yum install –y gccyum install –y gcc-c++ 会自动安装成功。 解压缩命令：tar –zxvf autoconf-2.61.tar.gz其他安装包一样。依次解压。 make 命令1Yum install -y make 安装库文件安装libxml2123# cd /usr/local/src/libxml2-2.6.30​# ./configure --prefix=/usr/local/libxml2# make &amp;&amp; make install 安装libmcrypt123# cd /usr/local/src/libmcrypt-2.5.8# ./configure --prefix=/usr/local/libmcrypt# make &amp;&amp; make install 安装zlib123# cd /usr/local/src/zlib-1.2.3# ./configure 注意：这里直接./configure 不用--prefix# make &amp;&amp; make install 安装libpng123# cd /usr/local/src/libpng-1.2.31# ./configure --prefix=/usr/local/libpng 注意：安装失败。原因很有可能是zlib 没有安装上# make &amp;&amp; make install 安装jpeg6这个软件包安装有些特殊，其它软件包安装时如果目录不存在，会自动创建，但这个软件包安装时需要手动创建。 12345678# mkdir /usr/local/jpeg6# mkdir /usr/local/jpeg6/bin# mkdir /usr/local/jpeg6/lib# mkdir /usr/local/jpeg6/include# mkdir -p /usr/local/jpeg6/man/man1# cd /usr/local/src/jpeg-6b# ./configure --prefix=/usr/local/jpeg6/ --enable-shared --enable-static# make &amp;&amp; make install 安装freetype1234# cd /usr/local/src/freetype-2.3.5# ./configure --prefix=/usr/local/freetype# make# make install 安装autoconf123# cd /usr/local/src/autoconf-2.61# ./configure# make &amp;&amp; make install 安装GD库123456789# cd /usr/local/src/gd-2.0.35# ./configure \\​--prefix=/usr/local/gd2/ \\​--enable-m4_pattern_allow \\​--with-zlib=/usr/local/zlib/ \\ --with-jpeg=/usr/local/jpeg6/ \\ --with-png=/usr/local/libpng/ \\ --with-freetype=/usr/local/freetype/# make 出现错误： 1234make[2]: *** [gd_png.lo] Error 1make[2]: Leaving directory `/usr/local/src/gd-2.0.35&apos;make[1]: *** [all-recursive] Error 1make[1]: Leaving directory `/usr/local/src/gd-2.0.35&apos;make: *** [all] Error 2 分析：这个问题是因为gd库中的gd_png.c这个源文件中包含png.h时，png.h没有找到导致的。 解决：在编译文件里 12# vi gd_png.c# 将include “png.h” 改成 include “/usr/local/libpng/include/png.h” 其中/usr/local/libpng/为libpng安装路径。 1# make install 开启80、3306端口1vi /etc/sysconfig/iptables 添加 12-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT 重启防火墙 1service iptables restart 关闭selinux修改/etc/selinux/config 文件 12vi /etc/selinux/config# 将SELINUX=enforcing改为SELINUX=disabled 重启防火墙 1service iptables restart 安装 Apache安装Apache123456789101112# cd /usr/local/src/httpd-2.2.9# ./configure \\ --prefix=/usr/local/apache2 \\ --sysconfdir=/etc/httpd \\ --with-z=/usr/local/zlib \\ --with-included-apr \\ --enable-so \\ --enable-deflate=shared \\ --enable-expires=shared \\ --enable-rewrite=shared \\ --enable-static-support# make &amp;&amp; make install 配置Apache启动Apache 1#/usr/local/apache2/bin/apachectl start 如果提示httpd: Could not reliably determine the server’s fully qualified domain name, using ::1 for ServerName 1vi /etc/http/httpd.conf 将里面的#ServerName www.example.com:80注释去掉,改成ServerName localhost:80 即可。再启动httpd 关闭Apache 1# /usr/local/apache2/bin/apachectl stop 查看80端口是否开启 ，之前我们已经开启 1# netstat -tnl|grep 80 然后可以通过浏览器访问http://localhost:80，如果页面显示正常显示测试页面，即表示apache已安装并启动成功。 添加自启动 1# echo &quot;/usr/local/apache2/bin/apachectl start&quot; &gt;&gt; /etc/rc.d/rc.local 安装 Mysqlcmake的安装12345[root@localhost]# tar -zxv -f cmake-2.8.10.2.tar.gz // 解压压缩包[root@localhost local]# cd cmake-2.8.10.2[root@localhost cmake-2.8.10.2]# ./configure[root@localhost cmake-2.8.10.2]# make[root@localhost cmake-2.8.10.2]# make install 将cmake永久加入系统环境变量用vi在文件/etc/profile文件中增加变量，使其永久有效， 1[root@localhost local]# vi /etc/profile 在文件末尾追加以下两行代码： 1PATH=/usr/local/cmake-2.8.10.2/bin:$PATHexport PATH 执行以下代码使刚才的修改生效： 1[root@localhost local]# source /etc/profile 用 export 命令查看PATH值 1[root@localhost local]# echo $PATH 注意：也可以直接yum install –y cmake 安装 yum install -y ncurses-devel必须安装，不然会出错 创建mysql的安装目录及数据库存放目录12[root@localhost]# mkdir -p /usr/local/mysql //安装mysql[root@localhost]# mkdir -p /usr/local/mysql/data //存放数据库 创建mysql用户及用户组1[root@localhost] groupadd mysql[root@localhost] useradd -r -g mysql mysql 编译安装mysql12345678910111213141516[root@localhost local]# tar -zxv -f mysql-5.5.45.tar.gz //解压[root@localhost local]# cd mysql-5.5.45 cmake -DCMAKE_INSTALL_PREFIX=/usr/local/mysql \\ -DMYSQL_UNIX_ADDR=/tmp/mysql.sock \\ -DDEFAULT_CHARSET=utf8 \\ -DDEFAULT_COLLATION=utf8_general_ci \\ -DWITH_EXTRA_CHARSETS=all \\ -DWITH_MYISAM_STORAGE_ENGINE=1 \\ -DWITH_INNOBASE_STORAGE_ENGINE=1 \\ -DWITH_MEMORY_STORAGE_ENGINE=1 \\ -DWITH_READLINE=1 \\ -DENABLED_LOCAL_INFILE=1 \\ -DMYSQL_DATADIR=/usr/local/mysql/data \\ -DMYSQL_USER=mysql[root@localhost mysql-5.5.45]# make[root@localhost mysql-5.5.45]# make install 检验是否安装成功1234[root@localhost mysql-5.5.45]# cd /usr/local/mysql/[root@localhost mysql]# lsbin COPYING data docs include INSTALL-BINARY lib man mysql-test README scripts share sql-bench support-files 有bin等以上文件的话，恭喜你已经成功安装了mysql。 设置mysql目录权限12345[root@localhost mysql]# cd /usr/local/mysql //把当前目录中所有文件的所有者设为root，所属组为mysql[root@localhost mysql]# chown -R root:mysql .[root@localhost mysql]# chown -R mysql:mysql data 将mysql的启动服务添加到系统服务中1[root@localhost mysql]# cp support-files/my-medium.cnf /etc/my.cnfcp：是否覆盖&quot;/etc/my.cnf&quot;？ y 创建系统数据库的表12[root@localhost mysql]# cd /usr/local/mysql[root@localhost mysql]# scripts/mysql_install_db --user=mysql 设置环境变量1[root@localhost ~]# vi /root/.bash_profile 修改为： 12PATH=$PATH:$HOME/bin:/usr/local/mysql/bin:/usr/local/mysql/lib[root@localhost ~]# source /root/.bash_profile //使刚才的修改生效 手动启动mysql12[root@localhost ~]# cd /usr/local/mysql[root@localhost mysql]# ./bin/mysqld_safe --user=mysql &amp; //启动MySQL，但不能停止 1mysqladmin -u root -p shutdown //此时root还没密码，所以为空值，提示输入密码时，直接回车即可。 将mysql的启动服务添加到系统服务中1[root@localhost mysql]# cp support-files/mysql.server /etc/init.d/mysql 启动mysql1[root@localhost mysql]# service mysql startStarting MySQL... ERROR! The server quit without updating PID file (/usr/local/mysql/data/localhost.localdomain.pid). 启动失败：我这里是权限问题，先改变权限 1[root@localhost mysql]# chown -R mysql:mysql /usr/local/mysql 接着启动服务器 1[root@localhost mysql]# /etc/init.d/mysql start 修改MySQL的root用户的密码以及打开远程连接123456789[root@localhost mysql]# mysql -u root mysqlmysql&gt; use mysql;mysql&gt; desc user;mysql&gt; GRANT ALL PRIVILEGES ON *.* TO root@&quot;%&quot; IDENTIFIED BY &quot;root&quot;; //为root添加远程连接的能力mysql&gt; update user set Password = password(&apos;123456&apos;) where User=&apos;root&apos;; //设置root用户密码mysql&gt; select Host,User,Password from user where User=&apos;root&apos;;mysql&gt; flush privileges;mysql&gt; exit; 重新登录1[root@localhost mysql]# mysql -u root -pEnter password:123456 若还不能进行远程连接，关闭防火墙 1[root@localhost]# /etc/rc.d/init.d/iptables stop 安装 php安装PHP12345678910111213141516# cd /usr/local/src/php-5.3.8# ./configure \\ --prefix=/usr/local/php \\ --with-config-file-path=/usr/local/php/etc \\ --with-apxs2=/usr/local/apache2/bin/apxs \\ --with-mysql=/usr/local/mysql/ \\ --with-libxml-dir=/usr/local/libxml2/ \\ --with-png-dir=/usr/local/libpng/ \\ --with-jpeg-dir=/usr/local/jpeg6/ \\ --with-freetype-dir=/usr/local/freetype/ \\​--with-gd=/usr/local/gd2/ \\ --with-zlib-dir=/usr/local/zlib/ \\​--with-mcrypt=/usr/local/libmcrypt/ \\​--with-mysqli=/usr/local/mysql/bin/mysql_config \\​--enable-mbstring=all \\​--enable-sockets 1# make &amp;&amp; make install 配置PHP创建配置文件 1# cp php.ini-development /usr/local/php/etc/php.ini 使用vi编辑apache配置文件 1# vi /etc/httpd/httpd.conf 最后一行添加这一条代码 1Addtype application/x-httpd-php .php .phtml 重启Apache 1# /usr/local/apache2/bin/apachectl restart 测试编写info.php文件，查看php配置详细1#vi /usr/local/apache2/htdocs/info.php","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"},{"name":"CentOS","slug":"CentOS","permalink":"http://phachon.github.io/tags/CentOS/"},{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/tags/Mysql/"},{"name":"Apache","slug":"Apache","permalink":"http://phachon.github.io/tags/Apache/"}]},{"title":"浅析 php 的几种运行方式","slug":"php-run-type","date":"2016-07-28T16:00:00.000Z","updated":"2018-09-13T13:02:05.665Z","comments":true,"path":"2016/07/29/php-run-type/","link":"","permalink":"http://phachon.github.io/2016/07/29/php-run-type/","excerpt":"PHP 的几种运行方式 CGI FAST-CGI Web-module CLI","text":"PHP 的几种运行方式 CGI FAST-CGI Web-module CLI CGICGI (Common Gateway Interface) 是通用网关型接口,CGI是外部应用程序（CGI程序）与Web服务器之间的接口标准，是在CGI程序和Web服务器之间传递信息的过程。简单的说，就是当你的 php引擎和web服务器相互传递消息时，CGI 规定了一套标准来规范如何传递数据以及数据传递的格式。 当 web 服务器接收到一个请求时，就会启动一个 CGI 进程，这里就会通知到PHP 引擎，然后去解析 php.ini 文件，开始处理请求，并且将处理的请求的结果以标准的格式返回给 web 服务器，并退出进程。 12345title:CGI工作原理浏览器-&gt;web服务器:发送请求web服务器-&gt;CGI应用程序(php引擎):启动一个 CGI 进程CGI应用程序(php引擎)-&gt;web服务器:发送解析好的信息web服务器-&gt;浏览器:发送 html 信息 显而易见的是，这样每一个请求过来的话都会重新去启动一个 CGI 进程,关键是每个进程又都会去启动引擎去解析 php.ini 文件，这样当请求多的时候，效率会非常的低。因而，已经逐渐被抛弃。 注意：需要明确的是 CGI 只是一套接口标准，具体的实现程序才是用来启动进程的。比如根据 CGI 实现的 php-cgi 程序。 FAST-CGI既然 CGI 是如此的效率低下，聪明的人类肯定能够想出更好的方法来使得 CGI 更加高效，对的，这就是 FAST-CGI。 FAST-CGI 也是一种通用网关型接口，是建立在 CGI 的基础上进化而来,FastCGI 像是一个常驻(long-live)型的 CGI，它可以一直执行着，只要激活后，不会每次都要花费时间去fork一次(这是CGI最为人诟病的fork-and-execute 模式)。它还支持分布式的运算, 即 FastCGI 程序可以在网站服务器以外的主机上执行并且接受来自其它网站服务器来的请求。简单理解呢，大概是这样：当web服务器启动时，会载入Fast-CGI 进程管理器，FastCGI进程管理器会同时开启多个 CGI 子进程，相当于一个进程池，当 web 请求到来时，会选择一个 CGI 解释器并连接，处理完成后将信息返回给web服务器，这时候，该子进程又会回到进程管理器中继续等待下一个连接，所以这样不需要每次都去重新启动进程，加载配置文件。 123456title:fast-cgi 工作原理web服务器-&gt;fastcgi进程管理:启动载入fastcgi进程管理-&gt;cgi子进程:启动多个web服务器-&gt;fastcgi进程管理:请求fastcgi进程管理-&gt;cgi子进程:连接一个cgi子进程-&gt;web服务器:返回解析并重新等待新的请求 php-cgi 只是用来处理 cgi 进程的程序，那 php fast-cgi 进程管理器是怎么实现的呢，php-fpm ,对的，就是它，php-fmp 用来管理和调度这些 php fast-cgi 进程。 注意：还是需要明确一下，fast-cgi 也只是一套协议标准，php fast-cgi才是具体的实现程序，php-fpm是实现了对 fast-cgi 的进程管理。 Web-module这个简称为 web 模块加载模式，想必用 apache 搭建过 php 环境的应该都了解，apahce 需要加载 mod-php5 模块，这个模块就是用来将 Apache 传递过来的 php 文件的请求，并处理这些请求，最终将处理的结果返回给 apache。在 apache 的配置文件中配置好了 php 模块，php 模块就会通过注册 apache2 的 ap_hook_post_config 挂钩，实现请求与返回。 windows 下： 1LoadModule php5_module d:/server/php/php5apache2_2.dll linux 下： 1LoadModule php5_module modules/mod_php5.so 该模块是 apache 在CGI的基础上进行的一种扩展，加快PHP的运行效率 CLIphp-CLI：PHP Command Line Interface 即 php 在命令行运行的接口，当然是相对于以上三种方式（web 请求）来说的 优点： 多进程池，子进程完成后，内核会回收掉 主进程只进行任务分发 CLI 模式在 windows 和 linux 都可以运行。 以上就是 php 的几种主要的运行方式，除此之外，还有一种运行方式是 ISAPI（Internet Server Application Program Interface）是微软提供的一套面向Internet服务的API接口，在这里就不多介绍了。因为现在几乎都是在 Linux 下部署 php 应用了。","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"},{"name":"CGI","slug":"CGI","permalink":"http://phachon.github.io/tags/CGI/"},{"name":"FAST-CGI","slug":"FAST-CGI","permalink":"http://phachon.github.io/tags/FAST-CGI/"},{"name":"PHP-FPM","slug":"PHP-FPM","permalink":"http://phachon.github.io/tags/PHP-FPM/"},{"name":"CLI","slug":"CLI","permalink":"http://phachon.github.io/tags/CLI/"}]},{"title":"Linux 常用命令总结","slug":"linux-command","date":"2016-07-27T16:00:00.000Z","updated":"2018-09-13T13:02:05.663Z","comments":true,"path":"2016/07/28/linux-command/","link":"","permalink":"http://phachon.github.io/2016/07/28/linux-command/","excerpt":"系统相关 who 显示在线登录用户 whoami 显示当前操作的用户 hostname 主机名 top 显示当前耗费最多的进程以及内存消耗 ps -aux 显示所有的进程信息 df 查看磁盘所占大小 -h 带单位 ifconfig 网络信息 ping 测试网络连接 netstat 网络状态信息 kill 杀死进程 clear 清屏 shutdown -r 关机重启 -h 关机不重启 now 立刻关机 reboot 重启","text":"系统相关 who 显示在线登录用户 whoami 显示当前操作的用户 hostname 主机名 top 显示当前耗费最多的进程以及内存消耗 ps -aux 显示所有的进程信息 df 查看磁盘所占大小 -h 带单位 ifconfig 网络信息 ping 测试网络连接 netstat 网络状态信息 kill 杀死进程 clear 清屏 shutdown -r 关机重启 -h 关机不重启 now 立刻关机 reboot 重启 目录相关 cd 切换目录 ls 列出目录下的文件或文件夹 -l 列出文件详细信息 -s 列出所有的文件及目录（包括隐藏） -f 列出的文件显示文件类型 mkdir 创建目录 -p 递归创建(父级不存在创建) pwd 显示当前目录路径 rmdir 删除目录 du 查看目录所占大小 -h 带有单位显示目录所占大小 zip 打包成 zip 文件 unzip 解压 zip 文件 tar 打包压缩 -c 归档文件 -x 解压 -z gzip压缩文件 -j bzip2压缩文件 -v 显示压缩或解压缩过程 -f 使用档名压缩：tar -zcvf /home/test.tar.gz /home/test解压：tar -zxvf test.tar.gz ./ 用户权限相关 useradd 添加用户 -c 注释信息 -d 目录指定用户主目录，如果此目录不存在，则同时使用-m选项，可以创建主目录 -g 用户组 指定用户所属的用户组 -G 用户组，用户组指定用户所属的附加组 -s Shell文件 指定用户的登录Shell -u 用户号 指定用户的用户号，如果同时有-o选项，则可以重复使用其他用户的标识号 useradd –d /usr/sam -m sam usermod 修改用户 参数和 useradd 一样 userdel 删除用户 -r 连同目录一起删除 普通用户增加 root 权限 修改 /etc/sudoers 文件，找到下面一行，把前面的注释（#）去掉12Allows people in group wheel to run all commands%wheel ALL=(ALL) ALL 然后修改用户，使其属于root组（wheel），命令如下： 1usermod -g root phachon 修改完毕，现在可以用 phachon 帐号登录，然后用命令 su - ，即可获取root 权限 sudo 命令可以不需要 root 密码来以 root 的权限执行 修改 /etc/sudoers 文件，找到下面一行，在root下面添加一行，如下所示： 1234Allow root to run any commands anywhereroot ALL=(ALL) ALLphachon ALL=(ALL) ALL #sudo 需要密码 phachon ALL=(ALL) NOPASSWD:ALL # sudo 不需要密码 ok , 你就可以用 root 权限了 chown 更改文件的用户用户组 sudo chown [-R] owner[:group] {File|Directory} 1sudo chown redis:redis ./redis 更改文件权限 首先先来了解一下三种基本权限r -&gt; 读 数值表示为 4w -&gt; 写 数值表示为 2x -&gt; 可执行 数值表示为 1 假如某一个文件的权限为 -rw-rw-r– -rw-rw-r–一共十个字符，分成四段。第 1 个字符“-”表示普通文件，“l”链接，“d”表示目录第2、3、4个字符“rw-”表示当前所属用户的权限，所以用数值表示为4+2=6第5、6、7个字符“rw-”表示当前所属组的权限，所以用数值表示为4+2=6第8、9、10个字符“r–”表示其他用户权限，所以用数值表示为2所以操作此文件的权限用数值表示为662 777 对应的权限是 -rwxrwxrwx 1sudo chmod 0777 test.php 修改 test.php 权限为 777","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://phachon.github.io/tags/Linux/"}]},{"title":"PHP 魔术方法之 __call 与 __callStatic","slug":"php-call-callStatic","date":"2016-07-27T16:00:00.000Z","updated":"2018-09-13T13:02:05.665Z","comments":true,"path":"2016/07/28/php-call-callStatic/","link":"","permalink":"http://phachon.github.io/2016/07/28/php-call-callStatic/","excerpt":"__call 方法的使用定义：在对象中调用一个不可访问方法时，__call() 会被调用。","text":"__call 方法的使用定义：在对象中调用一个不可访问方法时，__call() 会被调用。 示例： 12345678910111213141516171819202122&lt;?php/** * __call 测试 * @author phachon@163.com */class Test &#123; public function __construct() &#123; &#125; public function show() &#123; echo &quot;show 一下\\n&quot;; &#125; public function __call($method, $arguments) &#123; echo &quot;不可访问的方法都来我这里了\\n&quot;; &#125;&#125;$test = new Test(); $test-&gt;show();//输出: show 一下$test-&gt;close(); //输出: 不可访问的方法都来我这里来了 上面例子中调用 close 方法时不存在，所以被 __call 接收了。 但是如果调用类里面的方法是 protected 或者是 private 的时候，是否可以被 __call 接收呢？ 123456789101112131415161718192021222324252627282930313233&lt;?php/** * __call 测试 * @author phachon@163.com */class Test &#123; public function __construct() &#123; echo &quot;我是构造方法\\n&quot;; &#125; public function show() &#123; echo &quot;show 一下\\n&quot;; &#125; public function __call($method, $arguments) &#123; echo &quot;不可访问的方法都来我这里了\\n&quot;; &#125; protected function _sing() &#123; echo &quot;我是唱歌的&quot;; &#125; private function _run() &#123; echo &quot;我是跑步的&quot;; &#125;&#125;$test = new Test();$test-&gt;show(); //输出：show 一下$test-&gt;_sing(); //输出：不可访问的方法都来我这里了$test-&gt;_run(); //输出：不可访问的方法都来我这里了$test-&gt;close(); //输出：不可访问的方法都来我这里了 事实证明除了没有定义的方法以及 private 和 protected 方法都会被魔术方法 __call 接收，所以定义为调用一个不可访问的方法时才被调用是十分准确的。（之前听有些人说是当访问一个未被定义的方法时被调用这是不准确的） 注意：__call 在使用时必须声明为 public 并且，方法必须有带两个参数，一个是 被调用的方法名，一个是方法携带的参数。 __callStatic 方法的使用定义：用静态方式中调用一个不可访问方法时，__callStatic() 会被调用。示例： 12345678910111213141516171819202122&lt;?php/** * __callStatic 测试 * @author phachon@163.com */class Test &#123; public function __construct() &#123; &#125; public static function show() &#123; echo &quot;show 一下\\n&quot;; &#125; public static function __callStatic($className, $arguments) &#123; echo &quot;不可访问的静态方法来这里吧&quot;; &#125;&#125;Test::show(); //输出：show 一下Test::close(); //输出：不可访问的静态方法来这里吧 同样对于没有定义的方法以及 private 和 protected 的静态方法，都会被__callStatic 接收。","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"}]},{"title":"Wamp 环境的搭建","slug":"wamp-install","date":"2016-07-25T16:00:00.000Z","updated":"2018-09-13T13:02:05.666Z","comments":true,"path":"2016/07/26/wamp-install/","link":"","permalink":"http://phachon.github.io/2016/07/26/wamp-install/","excerpt":"Apache下载Apache是一种b/s结构的软件，Apache属于s服务端 下载地址：http://httpd.apache.org/download.cgi 选择相应的版本下载 我这里下载的是 httpd-2.2.22-win32-x86-no_ssl.msi解释一下下载的文件：版本：2.2.22操作系统：win32 x86是否提供ssl: no_ssl 不提供","text":"Apache下载Apache是一种b/s结构的软件，Apache属于s服务端 下载地址：http://httpd.apache.org/download.cgi 选择相应的版本下载 我这里下载的是 httpd-2.2.22-win32-x86-no_ssl.msi解释一下下载的文件：版本：2.2.22操作系统：win32 x86是否提供ssl: no_ssl 不提供 安装(1) 双击点击下载好的文件：httpd-2.2.22-win32-x86-no_ssl.msi (2) 点击 next,进入协议页面，勾选同意。 (3) 点击两次 next 进入到服务器配置页面 (4) 点击next，进入配置模式，选择自定义配置模式 (5) 点击next，进入路径配置界面 在 D 盘下创建一个server 目录（不要使用中文）将安装路劲选择到创建是server目录，并在server目录下创建一个Apache目录 (6) 点击next，进入到准备安装界面，点击install进行安装，之后点击finish完成,在电脑的任务栏会出现 apache 的图标，绿色代表已开启 (7) 验证是否成功 在浏览器输入 http://localhost ，页面 输出 It, works! 证明安装成功。 (8) apache 安装后的目录结构说明 D:/server/apache 下 bin: Apache 的可执行文件 cgi-bin：CGI 可执行文件 conf：配置文件 error：错误日志 htdocs：网站默认根目录 icons：图标 logs：日志 modules：Apache 可加载的模块 D:server/apache/bin httpd.exe apache 的服务端 (9) 几个简单的 httpd 命令 M：Apache可以加载的模块（功能） l：当前Apache已经加载的模块 t：验证配置文件的语法错误 在cmd控制台下，进入到 Apache 的bin目录，使用 httpd.exe 或者httpd 命令+空格+参数 配置文件验证 修改Apache配置文件：Apache/conf/httpd.conf 1Servername www.test.com:80 #将前面的&apos;#&apos;号去掉即可开启 修改完配置文件后记得要重启 apache ,否则配置不会生效。 Mysql下载1mysql是一种c/s结构的软件。 当前是在为web服务器增加可以访问数据库的能力。下载地址：http://www.mysql.com/downloads/我这里下载的是:mysql-5.5-win32 安装(1) 双击文件，进入安装界面 (2) 点击next，进入协议界面，选中同意协议，点击next进入配置模式 (3) 点击自定义安装，进入路径配置界面 在 D 盘 server 下创建一个目录 mysql修改mysql的安装目录 修改数据路径 (4) 点击 next 进入到准备安装界面，点击install进行安装，安装完成之后进入到安装完成页面,勾选 finish 完成 (5) 点击next进行配置，进入到配置选择界面 (6) 选择详细配置，点击next，进入到服务器类型配置界面 (7) 选择开发者机器，点击next，进入数据库用途配置 (8) 选择多功能数据库，点击next，进入到InnoDB驱动选择界面，可以直接点击next跳过 (9) 配置并发选项 (10) 选择手动选择，设置为默认的并发量15个，点击next，进入网络设置界面 (11) 勾选防火墙放行，其他默认，点击next进入到字符集设置界面 (12) 选择手动选择，设置字符集为utf8，点击next进入windows设置 (13) 勾选设置环境变量，点击next进入安全选项配置 (14) 输入root用户的密码，点击next进入到准备配置的界面 (15) 点击excute执行配置项，需要上面的四项都成功打上勾才算配置成功,点击finish完成安装。 (16) 检测是否安装成功 cmd控制台输入mysql –uroot –proot (17) mysql 安装目录结构解释 bin：执行文件 data：数据存放目录 include：包含文件 lib：核心文件 share：共享文件 my.ini：mysql 核心配置文件 mysql 的 bin 目录 mysql.exe mysql 的客户端 mysqld.exe mysql 服务器端 配置PHP下载php 下载地址：http://www.php.net/downloads.php 选择对应的版本下载 配置在 D:server/ 下创建 php 目录,将下载的 php 文件压缩包解压到该文件夹下 (1) 配置 apache,让 apache 能够识别 php在Apache中加载PHP模块（把PHP当做Apache的一个模块来运行）。/apache/conf/httpd.conf 12LoadModule php5_module d:/server/php/php5apache2_2.dll #加载PHP，当做Apache的模块 加载模式：LoadModule 模块名（不能随意） 模块的动态链接库所在的AddType application/x-httpd-php .php #增加PHP处理模块需要处理的文件,将以.php结尾的文件交给PHP模块去处理 (2) 配置 php ，让 php 去连接 mysql PHP本身没有能力去操作mysql，需要借助外部扩展才可以。在PHP中，提供一套mysql的扩展，能够连接mysql服务器。 在 php 的安装目录下有两个配置文件 php.ini-development php.ini-production,复制一份，修改为 php.ini 文件。打开 php.ini 将php的配置文件，加载到Apache的配置文件中。 /apache/conf/httpd.conf 1PHPIniDir d:/server/php/php.ini #增加php配置文件的路径 开启mysql扩展。/php/php.ini 1;extesion=php_mysql.dll #将前面的 ; 号去掉即可开启 指定扩展文件所在的目录。/php/php.ini 12;extension_dir = &quot;ext&quot;extension_dir = d:server/php/ext 修改 php 时区 在php的配置文件中去修改。/php/php.ini 12;date_timezone = date_timezone = PRC #中国时区 配置虚拟主机Apache的虚拟主机分为两种：基于IP地址的虚拟主机，基于域名的虚拟主机 基于域名的虚拟主机：通过域名来是的Apache区分对应的网站（文件夹） Apache提供了多个位置可以用来配置虚拟主机，httpd.conf和/extra/httpd_vhost.confhttpd.conf配置之后，只需要直接重启Apache即可生效/extra/httpd_vhost.conf配置之后，需要在httpd.conf下加载对应的配置文件 先加载虚拟主机配置文件找到 Include conf/extra/http-vhosts.conf,并开启 创建虚拟主机1234&lt;VirtualHost *:80&gt; ServerName www.test.com #域名 DocumentRoot &quot;d:code/php/test&quot; #路径&lt;/VirtualHost&gt; 重启 apache修改 hosts 文件hosts文件路径：C:\\Windows\\System32\\drivers\\etc\\hosts 12127.0.0.1 localhost127.0.0.1 test.com 设置访问权限123456&lt;Directory &quot;d:code/php/test&quot;&gt; # 目录访问权限 Order Deny,Allow #设置顺序 Deny from all Allow from all DirectoryIndex indexs #指定访问方式，如果没有请求文件，而默认的文件又不存在，则显示所有的文件列表（在开发环境中应该禁用）&lt;/Directory&gt; 注意：一旦开启虚拟主机，那么默认的localhost会被覆盖，被第一个虚拟主机覆盖，为了解决不被覆盖的问题，需要额外增加一个localhost的虚拟主机。 123456789101112&lt;VirtualHost *:80&gt; ServerName localhost DocumentRoot &quot;d:server/apache/htdocs&quot; #网站根目录 &lt;Directory &quot;d:code/php/test&quot;&gt; # 目录访问权限 Order Deny,Allow #设置顺序 Deny from all Allow from all DirectoryIndex indexs #指定访问方式，如果没有请求文件，而默认的文件又不存在，则显示所有的文件列表（在开发环境中应该禁用） &lt;/Directory&gt;&lt;/VirtualHost&gt; 更加清晰的配置方法上面的配置方法是通用的配置虚拟主机的方式，但是随着越来越多的开发应用，会发现 Include conf/extra/http-vhosts.conf 里面会有越来越多的配置写在一起,有些早已不用的和正在使用的配置都加载在一起，不利于管理和修改。因此还可以采取以下的方式配置。 重新回到第1步中，打开 http.conf 文件，这次不要打开 Include conf/extra/http-vhosts.conf 的配置。而是在 http.conf 的最后一行添加 Include conf/extra/test.com.conf。 在 conf/extra 下面创建一个 test.com.conf 文件，然后将配置信息写入到文件中。 12345678910111213NameVirtualHost *:80&lt;VirtualHost *:80&gt; ServerAdmin phachon@163.com DocumentRoot &quot;D:/server/apache/htdocs/test&quot; DirectoryIndex index.php ServerName test.com &lt;Directory &quot;D:/server/apache/htdocs/test&quot;&gt; Options Indexes FollowSymLinks AllowOverride None Order allow,deny Allow from all &lt;/Directory&gt;&lt;/VirtualHost&gt; 以后每新增一个虚拟主机配置就在 http.conf 的最后一行加载一下，并在 conf/extra 下创建对应的 conf 文件。","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"},{"name":"Windows","slug":"Windows","permalink":"http://phachon.github.io/tags/Windows/"},{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/tags/Mysql/"},{"name":"Apache","slug":"Apache","permalink":"http://phachon.github.io/tags/Apache/"}]},{"title":"Web 网站的基本工作原理","slug":"web-work","date":"2016-07-25T16:00:00.000Z","updated":"2018-09-13T13:02:05.666Z","comments":true,"path":"2016/07/26/web-work/","link":"","permalink":"http://phachon.github.io/2016/07/26/web-work/","excerpt":"静态页访问 示例：http://www.test.com/index.html 请求步骤： (1) 用户输入需要访问的地址或者具体的网页文件(2) 开始域名解析,会先找到本地的 hosts 文件，然后再找网络上的 DNS 服务器,最终解析到 ip 地址(3) ip 地址所在机器的 Web 服务器接收这个请求，获取请求文件 index.html(4) web 服务器将这个文件的信息返回给用户所用的浏览器(5) 浏览器解析 html 代码，显示出数据 123456Title: 静态网页资源的访问流程图用户-&gt;浏览器:输入资源地址浏览器-&gt;域名解析(DNS):解析 ip域名解析(DNS)-&gt;web 服务器:根据 ip 找到服务器资源web 服务器-&gt;浏览器:返回资源给浏览器浏览器-&gt;用户:解析html显示","text":"静态页访问 示例：http://www.test.com/index.html 请求步骤： (1) 用户输入需要访问的地址或者具体的网页文件(2) 开始域名解析,会先找到本地的 hosts 文件，然后再找网络上的 DNS 服务器,最终解析到 ip 地址(3) ip 地址所在机器的 Web 服务器接收这个请求，获取请求文件 index.html(4) web 服务器将这个文件的信息返回给用户所用的浏览器(5) 浏览器解析 html 代码，显示出数据 123456Title: 静态网页资源的访问流程图用户-&gt;浏览器:输入资源地址浏览器-&gt;域名解析(DNS):解析 ip域名解析(DNS)-&gt;web 服务器:根据 ip 找到服务器资源web 服务器-&gt;浏览器:返回资源给浏览器浏览器-&gt;用户:解析html显示 动态页访问示例：http://www.test.com/test.php 请求步骤： (1) 用户浏览器输入网址以及请求的动态文件的脚本(2) 域名解析，先找本地 hosts ,再找 DNS(3) web 服务器接收请求,获取请求文件 test.php(4) web 服务器将 test.php 交给 php 引擎处理(5) php 引擎解析 php 代码,如果连接了数据库，就调用 mysql 扩展，去操作数据库，最终将解析成 html 文件(6) 将解析的 html 文件返回给 web 服务器(Apache)(7) web服务器返回 test.php 得到的最终 html 文件给浏览器(8) 浏览器解析html代码，显示数据 12345678title:动态网页的访问流程图用户-&gt;浏览器:输入动态脚本地址浏览器-&gt;域名解析(DNS):解析域名域名解析(DNS)-&gt;Web服务器(Apache):ip定位到机器Web服务器(Apache)-&gt;php引擎:发送test.phpphp引擎-&gt;Web服务器(Apache):将解析成html文件返回Web服务器(Apache)-&gt;浏览器:将html返回浏览器-&gt;用户:解析html显示 apache 的工作原理Apache的诸多功能都是通过模块进行加载的，自己本身并不具备那么多能力（功能）,下图以 php 为例 12345678title:Apache 的工作示意图浏览器-&gt;Apache:http://test.com/test.phpApache-&gt;php引擎:test.phpphp引擎-&gt;php扩展:mysql扩展php扩展-&gt;mysql数据库:连接mysqlmysql数据库-&gt;php引擎:返回数据给php引擎php引擎-&gt;Apache:解析成html返回Apache-&gt;浏览器:返回html给浏览器","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"},{"name":"Apache","slug":"Apache","permalink":"http://phachon.github.io/tags/Apache/"}]},{"title":"CentOS 下安装 Memcache 和 php 扩展","slug":"centos-install-memcache","date":"2016-07-25T16:00:00.000Z","updated":"2018-09-13T13:02:05.660Z","comments":true,"path":"2016/07/26/centos-install-memcache/","link":"","permalink":"http://phachon.github.io/2016/07/26/centos-install-memcache/","excerpt":"CentOS 下安装 Memcache 和 php memcache 扩展 下载安装查看相关软件包 1Yum search memcached 有了，可以进行安装了 1Yum -y install memcached","text":"CentOS 下安装 Memcache 和 php memcache 扩展 下载安装查看相关软件包 1Yum search memcached 有了，可以进行安装了 1Yum -y install memcached Memcache关联php 1yum -y install php-pecl-memcache 验证安装结果 12memcached -hphp -m | grep memcache Memcache的基本设置启动memcache的服务端： 1memcached -d -m 100 -u root -l 222.186.xx.xxx -p 11211 -c 512 -P /tmp/memcached.pid 参数说明-d 选项是启动一个守护进程；-m 是分配给Memcache使用的内存数量，单位是MB，我这里是100MB；-u 是运行Memcache的用户，我这里是root；-l 是监听的服务器IP地址我这里指定了服务器的IP地址222.186.xx.xxx；-p 是设置Memcache监听的端口，我这里设置了11211，最好是1024以上的端口；-c 选项是最大运行的并发连接数，默认是1024，我这里设置了512，按照你服务器的负载量来设定；-P 是设置保存Memcache的pid文件，我这里是保存在 /tmp/memcached.pid； 使用检查memcached是否启动 12Netstat -an | moretcp 0 0 222.186.xx.xxx:11211 0.0.0.0:* LIST 设置开机启动 1Chkconfig memcached on 启动和停止 12Service memcached start | stopOr /etc/init.d/memcached start | stop 重启centos 12Shutdown -r nowOr reboot 编写 php 文件来验证 memcache 是否可用吧。","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"},{"name":"CentOS","slug":"CentOS","permalink":"http://phachon.github.io/tags/CentOS/"},{"name":"Memcache","slug":"Memcache","permalink":"http://phachon.github.io/tags/Memcache/"}]},{"title":"CentOS下php安装 mcrypt 扩展","slug":"centos-install-php-mcrypt","date":"2016-07-24T16:00:00.000Z","updated":"2018-09-13T13:02:05.660Z","comments":true,"path":"2016/07/25/centos-install-php-mcrypt/","link":"","permalink":"http://phachon.github.io/2016/07/25/centos-install-php-mcrypt/","excerpt":"源码编译安装需要下载Libmcrypt,mhash,mcrypt安装包 下载地址：http://www.sourceforge.net libmcrypt(libmcrypt-2.5.8.tar.gz ); mcrypt(mcrypt-2.6.8.tar.gz ); mhash(mhash-0.9.9.9.tar.gz ); 123wget &quot;http://downloads.sourceforge.net/mcrypt/libmcrypt-2.5.8.tar.gz&quot;wget &quot;http://downloads.sourceforge.net/mcrypt/mcrypt-2.6.8.tar.gz&quot;wget &quot;http://downloads.sourceforge.net/mhash/mhash-0.9.9.9.tar.gz&quot;","text":"源码编译安装需要下载Libmcrypt,mhash,mcrypt安装包 下载地址：http://www.sourceforge.net libmcrypt(libmcrypt-2.5.8.tar.gz ); mcrypt(mcrypt-2.6.8.tar.gz ); mhash(mhash-0.9.9.9.tar.gz ); 123wget &quot;http://downloads.sourceforge.net/mcrypt/libmcrypt-2.5.8.tar.gz&quot;wget &quot;http://downloads.sourceforge.net/mcrypt/mcrypt-2.6.8.tar.gz&quot;wget &quot;http://downloads.sourceforge.net/mhash/mhash-0.9.9.9.tar.gz&quot; 安装Lmcrypt12345tar -zxvf libmcrypt-2.5.8.tar.gzcd libmcrypt-2.5.8./configuremakemake install #说明：libmcript默认安装在/usr/local 安装mhash12345tar -zxvf mhash-0.9.9.9.tar.gzcd mhash-0.9.9.9./configuremakemake install 安装mcrypt12345tar -zxvf mcrypt-2.6.8.tar.gzcd mcrypt-2.6.8LD_LIBRARY_PATH=/usr/local/lib ./configuremakemake install 安装php的mcrypt扩展(动态加载编译) 下载php下的mcrypt扩展或者直接下载php的完整安装包http://www.php.net/releases/ 网页下找到自己服务器的php版本，下载后tar解压（本人的是php5.3.3） 进入ext/mcrypt文件夹上传 mcrypt文件夹到你服务器的某个目录下然后进入此目录 执行phpize命令（phpize是用来扩展php扩展模块的，通过phpize可以建立php的外挂模块，如果没有？yum install php53-devel里包含了，或者其他方法） 1234567[root@phachon 14:48 mcrypt] whereis phpize #phpize是否存在phpize: /usr/bin/phpize /usr/share/man/man1/phpize.1.gz[root@phachon 14:48 mcrypt] phpizeConfiguring for:PHP Api Version: 20090626Zend Module Api No: 20090626Zend Extension Api No: 220090626 执行完后，会发现当前目录下多了一些configure文件，最后执行php-config命令就基本完成了执行以下命令，确保你的/usr/bin/php-config是存在的 123[root@phachon 15:02 mcrypt] whereis php-configphp-config: /usr/bin/php-config /usr/share/man/man1/php-config.1.gz[root@phachon 15:02 mcrypt] ./configure --with-php-config=/usr/bin/php-config 如果遇到以下错误，请先安装gcc，命令yum install gcc 1configure: error: no acceptable C compiler found in $PATH 直到不报错，出现：config.status: creating config.h，执行以下命令 1[root@phachon 15:06 mcrypt] make &amp;&amp; make install 提示如下，说明你安装成功 1Installing shared extensions: /usr/lib64/php/modules/ 顺便检查下/usr/lib64/php/modules/里的mrcypt.so扩展是否已经创建成功 然后的事就简单了，给你的php.ini添加一条extension=mcrypt.so 1[root@phachon 15:09 mcrypt] cd /etc/php.d 创建一个mrcypt.ini文件就行，里面写extension=mcrypt.so 1[root@phachon 15:17 php.d] echo &apos;extension=mcrypt.so&apos; &gt; mcrypt.ini 重启apache，phpinfo()，查看 mcrypt 模块扩展是不是加载了","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"},{"name":"CentOS","slug":"CentOS","permalink":"http://phachon.github.io/tags/CentOS/"},{"name":"mcrypt","slug":"mcrypt","permalink":"http://phachon.github.io/tags/mcrypt/"}]},{"title":"Lump yum 安装与搭建","slug":"lamp-yum-install","date":"2016-07-24T16:00:00.000Z","updated":"2018-09-13T13:02:05.663Z","comments":true,"path":"2016/07/25/lamp-yum-install/","link":"","permalink":"http://phachon.github.io/2016/07/25/lamp-yum-install/","excerpt":"准备配置防火墙，开启 80，3306 端口打开iptables 1vi /etc/sysconfig/iptables 允许80端口通过防火墙 1-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT 允许3306端口通过防火墙 1-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT 允许21端口通过防火墙1-A INPUT -m state --state NEW -m tcp -p tcp --dport 21 -j ACCEPT","text":"准备配置防火墙，开启 80，3306 端口打开iptables 1vi /etc/sysconfig/iptables 允许80端口通过防火墙 1-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT 允许3306端口通过防火墙 1-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT 允许21端口通过防火墙1-A INPUT -m state --state NEW -m tcp -p tcp --dport 21 -j ACCEPT 备注：把这两条规则添加到防火墙配置的最后一行，导致防火墙启动失败，正确的应该是添加到默认的22端口这条规则的下面 如下所示： 12345678910111213141516#Firewall configuration written by system-config-firewall#Manual customization of this file is not recommended.*filter:INPUT ACCEPT [0:0]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [0:0]-A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT-A INPUT -p icmp -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 21 -j ACCEPT-A INPUT -j REJECT --reject-with icmp-host-prohibited-A FORWARD -j REJECT --reject-with icmp-host-prohibitedCOMMIT 1/etc/init.d/iptables restart #最后重启防火墙使配置生效 关闭SELINUX12345678vi /etc/selinux/configSELINUX=enforcing #注释掉SELINUXTYPE=targeted #注释掉SELINUX=disabled #增加:wq #保存，关闭shutdown -r now #重启系统 安装安装Apache1yum install httpd #根据提示，输入 y 安装即可 1/etc/init.d/httpd start #启动 Apache 备注：Apache 启动后可能会报错： 1正在启动 httpd:httpd: Could not reliably determine the server&apos;s fully qualif domain name, using ::1 for ServerName 解决办法： 1vi /etc/httpd/conf/httpd.conf 找到 #ServerName www.example.com:80修改为 ServerName www.osyunwei.com:80 #这里设置为你自己的域名，如果没有域名，可以设置为localhost 123:wq! #保存退出chkconfig httpd on #设为开机启动/etc/init.d/httpd restart #重启Apache 安装Mysql安装1yum install mysql mysql-server #询问是否安装，输入Y自动安装 1/etc/init.d/mysqld start #启动MySQL 1chkconfig mysqld on #设为开机启动 1cp /usr/share/mysql/my-medium.cnf /etc/my.cnf #拷贝配置文件（注意：如果/etc目录下面默认有一个my.cnf，直接覆盖即可） 为 root 账户设置密码1mysql_secure_installation 回车，根据提示输入Y输入2次密码，回车根据提示一路输入Y最后出现：Thanks for using MySQL!MySql密码设置完成，重新启动 MySQL： 123/etc/init.d/mysqld restart #重启/etc/init.d/mysqld stop #停止/etc/init.d/mysqld start #启动 安装PHP5(1) 安装 1yum install php #根据提示输入Y直到安装完成 (2) 安装 php 组件，使 PHP5 支持Mysql 1yum install php-mysql php-gd libjpeg* php-imap php-ldap php-odbc php-pear php-xml php-xmlrpc php-mbstring php-mcrypt php-bcmath php-mhash libmcrypt 这里选择以上安装包进行安装根据提示输入Y回车 12/etc/init.d/mysqld restart #重启MySql/etc/init.d/httpd restart #重启Apche 配置Apache 配置1vi /etc/httpd/conf/httpd.conf #编辑 apache 配置文件 12345678910111213ServerTokens OS #在44行 修改为：ServerTokens Prod （在出现错误页的时候不显示服务器操作系统的名称）ServerSignature On #在536行 修改为：ServerSignature Off （在错误页中不显示Apache的版本）Options Indexes FollowSymLinks #在331行 修改为：Options Includes ExecCGI FollowSymLinks #允许服务器执行CGI及SSI，禁止列出目录AddHandler cgi-script .cgi #在796行 修改为：AddHandler cgi-script .cgi .pl （允许扩展名为.pl的CGI脚本运行）AllowOverride None #在338行 修改为：AllowOverride All （允许.htaccess）AddDefaultCharset UTF-8 #在759行 修改为：AddDefaultCharset GB2312 （添加GB2312为默认编码）Options Indexes MultiViews FollowSymLinks #在554行 修改为Options MultiViews FollowSymLinks #不在浏览器上显示树状目录结构DirectoryIndex index.html index.html.var #在402行 修改为DirectoryIndex index.html index.htm Default.html Default.htmindex.php Default.php index.html.var （设置默认首页文件，增加index.php）KeepAlive Off #在76行 修改为：KeepAlive On （允许程序性联机）MaxKeepAliveRequests 100 #在83行 修改为 MaxKeepAliveRequests 1000 （增加同时连接数） 123:wq! #保存退出/etc/init.d/httpd restart #重启rm -f /etc/httpd/conf.d/welcome.conf /var/www/error/noindex.html #删除默认测试页 php 配置1vi /etc/php.ini #编辑 12date.timezone = PRC #在946行 把前面的分号去掉，改为date.timezone = PRCdisable_functions = passthru,exec,system,chroot,scandir,chgrp,chown,shell_exec,proc_open,proc_get_status,ini_alter,ini_alter,ini_restore,dl,openlog,syslog,readlink,symlink,popepassthru,stream_socket_server,escapeshellcmd,dll,popen,disk_free_space,checkdnsrr,checkdnsrr,getservbyname,getservbyport,disk_total_space,posix_ctermid,posix_get_last_error,posix_getcwd, posix_getegid,posix_geteuid,posix_getgid, posix_getgrgid,posix_getgrnam,posix_getgroups,posix_getlogin,posix_getpgid,posix_getpgrp,posix_getpid, posix_getppid,posix_getpwnam,posix_getpwuid, posix_getrlimit, posix_getsid,posix_getuid,posix_isatty, posix_kill,posix_mkfifo,posix_setegid,posix_seteuid,posix_setgid, posix_setpgid,posix_setsid,posix_setuid,posix_strerror,posix_times,posix_ttyname,posix_uname 在386行 列出PHP可以禁用的函数，如果某些程序需要用到这个函数，可以删除，取消禁用。 12345expose_php = Off #在432行 禁止显示php版本的信息magic_quotes_gpc = On #在745行 打开magic_quotes_gpc来防止SQL注入short_open_tag = ON #在229行支持php短标签open_basedir = .:/tmp/ #在380行 设置表示允许访问当前目录(即PHP脚本文件所在之目录)和/tmp/目录,可以防止php木马跨站,如果改了之后安装程序有问题，可以注销此行，或者直接写上程序的目录/data/www.osyunwei.com/:/tmp/:wq! #保存退出 12/etc/init.d/mysqld restart #重启MySql/etc/init.d/httpd restart #重启Apche","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"},{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/tags/Mysql/"},{"name":"CentOS 6.4","slug":"CentOS-6-4","permalink":"http://phachon.github.io/tags/CentOS-6-4/"},{"name":"Apache","slug":"Apache","permalink":"http://phachon.github.io/tags/Apache/"}]},{"title":"Linux网络配置","slug":"linux-network-config","date":"2016-07-23T16:00:00.000Z","updated":"2018-09-13T13:02:05.664Z","comments":true,"path":"2016/07/24/linux-network-config/","link":"","permalink":"http://phachon.github.io/2016/07/24/linux-network-config/","excerpt":"配置网络信息1vim /etc/sysconfig/network-scripts/ifcfg-eth0 打开ifcfg-eth0这个文件 在这个文件中，保存了第一块网卡的配置信息 DEVICE ：设备名 ONBOOT ：当系统启动后是否自动启动网卡设备 BOOTPROTO ：获取IP方式 static：静态获取 IPADDR ：ip地址 NETMASK ：子网掩码 GATEWAY ：网关","text":"配置网络信息1vim /etc/sysconfig/network-scripts/ifcfg-eth0 打开ifcfg-eth0这个文件 在这个文件中，保存了第一块网卡的配置信息 DEVICE ：设备名 ONBOOT ：当系统启动后是否自动启动网卡设备 BOOTPROTO ：获取IP方式 static：静态获取 IPADDR ：ip地址 NETMASK ：子网掩码 GATEWAY ：网关 如果没有IPADDR ：ip地址则添加IPADDR=自己设置的ip地址修改ONBOOT=”yes” BOOTPROTO=”static”修改完后： :wq 或者 :x 保存退出 启动网络设备(1) service 1service network start|restart|stop (2) ifup、ifdown ifup：启用ifdown：关闭 1ifup eth0 ifdown eth0 测试网络连接(1) ifconfig 查看当前网络设备 (2) ping 说明网络连接成功。","categories":[{"name":"Coding","slug":"Coding","permalink":"http://phachon.github.io/categories/Coding/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"http://phachon.github.io/tags/CentOS/"},{"name":"Linux","slug":"Linux","permalink":"http://phachon.github.io/tags/Linux/"}]}]}